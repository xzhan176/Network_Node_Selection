{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Twitter data\n",
    "s_df = pd.read_csv('preprocess-twitter/opinion_twitter.txt', sep = '\\t', header = None)\n",
    "w_df = pd.read_csv('preprocess-twitter/edges_twitter.txt', sep = '\\t', header = None)\n",
    "# number of vertices\n",
    "n = len(s_df[0].unique())\n",
    "s_df.columns = [\"ID\", \"Tick\", \"Opinion\"]\n",
    "# we take the opinion from the last appearance of the vertex ID in the list as its innate opinion\n",
    "s = s_df.groupby([\"ID\"]).last()[\"Opinion\"].values.reshape(n, 1)\n",
    "\n",
    "\n",
    "# create adjacency matrix\n",
    "G = np.zeros((n, n))\n",
    "for i in range(1, n + 1):\n",
    "    idx = np.where(w_df[0].values == i)[0]\n",
    "    js = w_df[1].values[idx]\n",
    "    for j in js:\n",
    "        G[i-1, j-1] = 1\n",
    "        G[j-1, i-1] = 1\n",
    "        \n",
    "    idx = np.where(w_df[1].values == i)[0]\n",
    "    js = w_df[0].values[idx]\n",
    "    for j in js:\n",
    "        G[i-1, j-1] = 1\n",
    "        G[j-1, i-1] = 1\n",
    "        \n",
    "L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "m = num_edges(L, n)                    # call the function to calculate the number of edges\n",
    "# what the twitter graph looks like \n",
    "nxG = nx.from_numpy_matrix(G)          \n",
    "plt.figure(figsize=(20, 20))\n",
    "# nx.draw(nxG)\n",
    "columnsum_ij = np.sum(A, axis=0)\n",
    "# print(columnsum_ij)\n",
    "print(n)\n",
    "\n",
    "\n",
    "# what the twitter graph looks like \n",
    "s_use = s.flatten()   # Convert array to a list for later operation\n",
    "s_use = s_use.tolist()\n",
    "new_s = [i * 30 for i in s_use]\n",
    "df = pd.DataFrame(new_s, columns=['Opinion']) #create a datafram with index at column 1, opinion at column 2\n",
    "\n",
    "\n",
    "nxG = nx.from_numpy_matrix(G)   \n",
    "# nxG = nx.relabel_nodes(nxG, mapping)      \n",
    "plt.figure(figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_anl(s,n,G,agent):\n",
    "\n",
    "    print(str(agent)+' opinion: ' + str(s[agent]))\n",
    "    print(str(agent)+' neighbors: '+ str(np.nonzero(G[agent])))\n",
    "\n",
    "    s_aa = s[:, 0]\n",
    "    my_dict = {index: value for index, value in enumerate(s_aa)}\n",
    "    sorting_s = sorted(my_dict.items(), key=lambda x:x[1])\n",
    "    sorted_S = dict(sorting_s)\n",
    "\n",
    "    temp = list(sorted_S.items()) \n",
    "    res = [idx for idx, key in enumerate(temp) if key[0]==agent]\n",
    "    # printing result \n",
    "    print(\"Opinion rank of this agent is : \" + str(res))\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"___________________Max Analyze__________________________________________\")\n",
    "    nxG = nx.from_numpy_matrix(G) \n",
    "    # G = nx.karate_club_graph()\n",
    "    print(\"_______________Degree Centrality___________________\")  \n",
    "    deg_centrality = nx.degree_centrality(nxG)\n",
    "    sortedDict = sorted(deg_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict = dict(sortedDict)\n",
    "    temp1 = list(converted_dict.items()) \n",
    "    res1 = [idx for idx, key in enumerate(temp1) if key[0]==agent]\n",
    "    print(\"rank of this agent is : \" + str(res1))\n",
    "    print(converted_dict[agent])\n",
    "\n",
    "    # print(converted_dict)\n",
    "    print(\"                           \")\n",
    "    print(\"_______________Closeness Rank________________________\")\n",
    "    close_centrality = nx.closeness_centrality(nxG)\n",
    "    sortedDict1 = sorted(close_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict1 = dict(sortedDict1)\n",
    "    temp2 = list(converted_dict1.items()) \n",
    "    res2 = [idx for idx, key in enumerate(temp2) if key[0]==agent]\n",
    "    print(\"rank of this agent is : \" + str(res2))\n",
    "    print(converted_dict1[agent])\n",
    "    # print(converted_dict1)\n",
    "    print(\"                           \")\n",
    "    print(\"_______________Page Rank_____________________________\")\n",
    "    pr = nx.eigenvector_centrality(nxG)\n",
    "    sortedDict3 = sorted(pr.items(), key=lambda x:x[1])\n",
    "    converted_dict3 = dict(sortedDict3)\n",
    "    temp3 = list(converted_dict3.items()) \n",
    "    res3 = [idx for idx, key in enumerate(temp3) if key[0]==agent]\n",
    "    print(\"rank of this agent is : \" + str(res3))\n",
    "    print(converted_dict3[agent])\n",
    "    # print(converted_dict3)\n",
    "\n",
    "    print(\"                           \")\n",
    "\n",
    "    def gap(op, n):\n",
    "        ones = np.ones((n, 1))\n",
    "        x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "        return abs(x)\n",
    "\n",
    "    gap = gap(s,n)\n",
    "    my_gap = {index: value for index, value in enumerate(gap)}\n",
    "    sorting_gap = sorted(my_gap.items(), key=lambda x:x[1])\n",
    "    sorted_gap = dict(sorting_gap)\n",
    "    #print(sorted_gap)\n",
    "    temp4 = list(sorted_gap.items()) \n",
    "    res4 = [idx for idx, key in enumerate(temp4) if key[0]==agent]\n",
    "    print(\"Agent's opinion gap to mean opinion is ranked as: \" + str(res4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
