{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xzhan176/Network_Node_Selection/blob/main/Paralleling_Simulation_Less_Memory_12_16_2022_success!!.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0rz_DqZRAO2o"
      },
      "outputs": [],
      "source": [
        "##### This code is from Updated Testing Reddit - No Con- bias (Fictitious Play)-01092022\n",
        "##### This code replace the big real datanetwork with small sythetic network \n",
        "import scipy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from itertools import combinations\n",
        "import time\n",
        "import random\n",
        "from random import randint\n",
        "from scipy.stats import beta\n",
        "import pandas as pd\n",
        "import copy\n",
        "%matplotlib inline\n",
        "# %run Check_Derivation_of_Two_Opinions.ipynb\n",
        "#%run pure_strategy_selection.ipynb  #include simple selection algorithm\n",
        "import scipy.io\n",
        "import collections\n",
        "import sys\n",
        "from itertools import count\n",
        "from itertools import combinations\n",
        "from itertools import product\n",
        "import scipy.optimize\n",
        "import csv\n",
        "import os.path\n",
        "from math import comb\n",
        "from itertools import count\n",
        "from time import sleep\n",
        "import time\n",
        "import multiprocessing\n",
        "from multiprocessing import Process\n",
        "from multiprocessing import Queue\n",
        "from operator import itemgetter\n",
        "\n",
        "# Game Parameters\n",
        "# Game_rounds =200 # Rounds + 1- use for printing data\n",
        "memory = 50\n",
        "\n",
        "save_path = 'C:/Users/xzhan176/OneDrive/Misinfo Paper/Sythetic Network - less memory version/'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z4iXHCimchIp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1V_MLZjAO2q"
      },
      "source": [
        "    # Flexible Manual set condition \n",
        "      > initial starting node\n",
        "      > memory of the player \n",
        "    # Fixed initial condition + memeory = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEZ4Q6zhAO2r"
      },
      "source": [
        "## Mathmatic Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sspKxgdfAO2r"
      },
      "outputs": [],
      "source": [
        "# centers the opinion vector around 0\\n\",\n",
        "def mean_center(op, n):\n",
        "    ones = np.ones((n, 1))\n",
        "    x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
        "    return x\n",
        "    \n",
        "# compute number of edges, m\\n\n",
        "def num_edges(L, n):\n",
        "    m = 0\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i > j and L[i,j] < 0:\n",
        "                m += 1            \n",
        "    return m\n",
        "\n",
        "# Compute number of possible actions\n",
        "def len_actions(k, n):\n",
        "    # create all combination of K opinions\n",
        "    max_option = [0, 1]  \n",
        "    k_opinions =list(product(max_option, repeat=k))  # All k opinion combinations\n",
        "    len_kops = len(k_opinions) # - number of combinations exist\n",
        "    # Horizontal length of all possible actions\n",
        "    h = comb(n,k) * len_kops\n",
        "    return h\n",
        "\n",
        "\n",
        "# maximizing polarization only: \\\\bar{z}^T \\\\bar{z}   \n",
        "def obj_polarization(A, L, op, n):\n",
        "    op_mean = mean_center(op, n)\n",
        "    z_mean = np.dot(A, op_mean)\n",
        "    return np.dot(np.transpose(z_mean), z_mean)[0,0] \n",
        "\n",
        "# Calculate innate polarization\n",
        "def obj_innate_polarization(s, n):  \n",
        "#     np.set_printoptions(precision=5)\n",
        "    op_mean = mean_center(s, n)\n",
        "    return np.dot(np.transpose(op_mean), op_mean)[0,0]\n",
        "\n",
        "np.set_printoptions(precision=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qblyOWFDAO2s",
        "outputId": "acc03668-20c8-4cca-e58b-07b4d63fb620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19800\n"
          ]
        }
      ],
      "source": [
        "k = 2\n",
        "n = 100\n",
        "# #comb(n,k)\n",
        "h = len_actions(k, n)\n",
        "print(h)\n",
        "np.set_printoptions(precision=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Rab6BWqFAO2s"
      },
      "outputs": [],
      "source": [
        "########### create all combination\n",
        "def cgen(i,n,k):\n",
        "    \"\"\"\n",
        "    returns the i-th combination of k numbers chosen from 1,2,...,n\n",
        "    \"\"\"\n",
        "    c = []\n",
        "    r = i+0\n",
        "    j = -1\n",
        "    for s in range(1,k+1):\n",
        "        cs = j+1\n",
        "        while r-comb(n-1-cs,k-s)>=0:\n",
        "            r -= comb(n-1-cs,k-s)\n",
        "            cs += 1\n",
        "        c.append(cs)\n",
        "        j = cs\n",
        "    return c\n",
        "# Create available combinations\n",
        "def convert_available(k_nodes, touched, k):\n",
        "    \n",
        "    #touched = list(set(touched)) #[2,4,6,8] unqie values of touched\n",
        "    touched.sort()\n",
        "    for i in touched: \n",
        "        for j in range(k): #[2,3,4,5,6,7,8,9]   \n",
        "            if k_nodes[j]>=i:\n",
        "                k_nodes[j] = k_nodes[j] + 1\n",
        "    return k_nodes\n",
        "\n",
        "# def creat_all_comb(i_th, n, k):\n",
        "# ########### create all combination of K opinions\n",
        "#     max_option = [0, 1]\n",
        "#     k_opinions =[]\n",
        "#     k_opinions = product(max_option, repeat=k)  # - all k opinion combinations\n",
        "#     k_nodes = cgen(i_th,n,k)\n",
        "#     return(k_nodes, k_opinions)\n",
        "\n",
        "def creat_all_comb(n, k):\n",
        "########### create all combination of K opinions\n",
        "    max_option = [0, 1]\n",
        "    k_opinions =[]\n",
        "    k_opinions = product(max_option, repeat=k)  # - all k opinion combinations\n",
        "    \n",
        "    return list(k_opinions)\n",
        "\n",
        "\n",
        "########### create available combination of K nodes\n",
        "def creat_available_comb(i_th, n,k,touched):\n",
        "\n",
        "    a = len(set(touched))  # number of unqiue touched nodes\n",
        "    len_nodesets = comb(n-a,k) #  number of available combination of k nodes\n",
        "    \n",
        "    k_fake = cgen(i_th,n-a,k) # generate the i-th list from total n-a agents\n",
        "    k_nodes = convert_available(k_fake, touched, k) # convert the i-th list to real k nodes\n",
        "\n",
        "    return (k_nodes)\n",
        "\n",
        "# output is changed opinion set based on inputs \n",
        "def change_k_innate_opinion(s, node_set, k_opinion): # node_set - 1 set  k_opinion- 1 set\n",
        "    op =  copy.copy(s) # make a copy of the innate opinion array \n",
        "\n",
        "    for j in range(k):\n",
        "        b = node_set[j] # b - agent index\n",
        "#         print('agent index' + str(b))\n",
        "#         print('op length'+ str(len(op)))\n",
        "#         print('k_opinions'+str(list(k_opinions)))\n",
        "        op[b]=k_opinion[j]   # f - index of which opinion combination\n",
        "\n",
        "    return op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_qWqYEZAO2t"
      },
      "outputs": [],
      "source": [
        "# i_th = 0\n",
        "# v2 = creat_available_comb(i_th, n,k,touched)\n",
        "# print(v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQAy_anpAO2t"
      },
      "outputs": [],
      "source": [
        "# # i = 4\n",
        "# # n = 20\n",
        "# # k = 2\n",
        "# # touched = [8, 17, 2, 6]\n",
        "# # creat_available_comb(i, n,k,touched)\n",
        "# k_nodes=[1,2]\n",
        "# touched = [2,3]\n",
        "# k = 2\n",
        "# convert_available(k_nodes, touched, k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwojG-i6AO2t"
      },
      "source": [
        "### 1. Import Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################ Make Innate Opinion ################################\n",
        "##create two set of weights connected with density 1) inviduals  2) individual & informaton Source\n",
        "c1 = np.sort(np.random.choice(n, n, replace=False)) #assume (1-r) are individuals\n",
        "print('c1')\n",
        "print(c1)\n",
        "l1 = len(c1)\n",
        "\n",
        "def make_innat_opinions(n, c1): # Make opinion for agents only - no info source is involved\n",
        "    \n",
        "    # Make list of ind innate opinion to define info source opinion\n",
        "    innat_s = np.random.uniform(low=0, high=1, size=int(n))   #individual's innate opinion \n",
        "\n",
        "    s = np.zeros((n, 1))\n",
        "    \n",
        "    idx1 = 0\n",
        "    for i in range(len(s)):\n",
        "        s[i] = innat_s[idx1]  #set innate opinion for ind.\n",
        "        idx1 += 1\n",
        "  \n",
        "    return s\n",
        "\n",
        "\n",
        "##################################Creating Adjacency Matrix ########################\n",
        "np.set_printoptions(precision=4)\n",
        "### Prepare for create adjacent matrix\n",
        "p1 = 0.9 # density within ind.\n",
        "p2 = 0 # density of edges between Info Source and Indivisuals\n",
        "\n",
        "pre_weights1 = scipy.sparse.random(1, int(0.5*l1*(l1 - 1)), density=p1).A[0] \n",
        "weights1 = pre_weights1/25\n",
        "\n",
        "\n",
        "# print(\"weight1\")\n",
        "# print(weights1)\n",
        "weights1.shape\n",
        "\n",
        "# b = weights2.round()  #generate a binary array to indicate the connection between ind. and inf. source \n",
        "                          #without consider the innate opinions, just based on the edges between info source and ind.\n",
        "\n",
        "    \n",
        "    \n",
        "# create n x n adjacency matrix with existing init_G\n",
        "G = np.zeros((n, n))\n",
        "    \n",
        "## Assign edges between ind to ind \n",
        "idx = 0\n",
        "for i in c1:\n",
        "    for j in c1:\n",
        "            if i == j:\n",
        "                G[i][j] =0\n",
        "                continue\n",
        "            elif i < j:\n",
        "                G[i][j] = weights1[idx]\n",
        "                idx += 1\n",
        "#                 print(idx)\n",
        "#                 print (G1[i][j])\n",
        "            else:\n",
        "                G[i][j] = G[j][i]\n",
        "print(\"G for agents completed!\")\n",
        "print(G)\n",
        "\n",
        "L = scipy.sparse.csgraph.laplacian(G, normed=False)\n",
        "A = np.linalg.inv(np.identity(n) + L)\n",
        "m = num_edges(L, n)\n",
        "columnsum_ij = np.sum(A, axis=0)\n",
        "print('Column Sum')\n",
        "print(columnsum_ij)\n",
        "# what the twitter graph looks like \n",
        "# nxG = nx.from_numpy_matrix(G)\n",
        "# plt.figure(figsize=(20, 20))\n",
        "# nx.draw(nxG)\n",
        "\n",
        "La = scipy.sparse.csgraph.laplacian(G, normed=False)\n",
        "\n",
        "nxG = nx.from_numpy_matrix(G)\n",
        "\n",
        "color_map = []\n",
        "for node in nxG:\n",
        "    if node in c1:\n",
        "        color_map.append('Blue')\n",
        "    else: \n",
        "        color_map.append('Red')  \n",
        "\n",
        "#nxG1 = nx.DiGraph(G)\n",
        "nx.draw(nxG, node_color=color_map, with_labels=False)\n",
        "plt.figure(figsize=(25, 25))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "y1_aVj2PEmPy",
        "outputId": "d4ffd66b-6072-4e9f-9708-1ff81118e267"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c1\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97 98 99]\n",
            "G for agents completed!\n",
            "[[0.     0.0346 0.0317 ... 0.031  0.0003 0.0243]\n",
            " [0.0346 0.     0.0041 ... 0.0019 0.017  0.0247]\n",
            " [0.0317 0.0041 0.     ... 0.0198 0.0319 0.    ]\n",
            " ...\n",
            " [0.031  0.0019 0.0198 ... 0.     0.0295 0.0257]\n",
            " [0.0003 0.017  0.0319 ... 0.0295 0.     0.003 ]\n",
            " [0.0243 0.0247 0.     ... 0.0257 0.003  0.    ]]\n",
            "Column Sum\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mGQnh3qjAO2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80bbb01d-6c99-4241-bbf3-63e0cafc68ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.6068]\n",
            " [0.6921]\n",
            " [0.4802]\n",
            " [0.8933]\n",
            " [0.9818]\n",
            " [0.2136]\n",
            " [0.7834]\n",
            " [0.3805]\n",
            " [0.7999]\n",
            " [0.7668]\n",
            " [0.2999]\n",
            " [0.5767]\n",
            " [0.6241]\n",
            " [0.0042]\n",
            " [0.5527]\n",
            " [0.4305]\n",
            " [0.9248]\n",
            " [0.7387]\n",
            " [0.9877]\n",
            " [0.0064]\n",
            " [0.2287]\n",
            " [0.4437]\n",
            " [0.3051]\n",
            " [0.6602]\n",
            " [0.926 ]\n",
            " [0.6594]\n",
            " [0.6734]\n",
            " [0.5458]\n",
            " [0.4557]\n",
            " [0.0884]\n",
            " [0.6838]\n",
            " [0.3335]\n",
            " [0.9031]\n",
            " [0.1629]\n",
            " [0.7096]\n",
            " [0.8683]\n",
            " [0.7099]\n",
            " [0.6483]\n",
            " [0.6596]\n",
            " [0.3402]\n",
            " [0.9531]\n",
            " [0.8684]\n",
            " [0.9705]\n",
            " [0.3547]\n",
            " [0.2642]\n",
            " [0.675 ]\n",
            " [0.2894]\n",
            " [0.0573]\n",
            " [0.8128]\n",
            " [0.261 ]\n",
            " [0.4823]\n",
            " [0.6507]\n",
            " [0.2898]\n",
            " [0.6669]\n",
            " [0.8081]\n",
            " [0.179 ]\n",
            " [0.7178]\n",
            " [0.4529]\n",
            " [0.7279]\n",
            " [0.003 ]\n",
            " [0.2306]\n",
            " [0.1507]\n",
            " [0.6485]\n",
            " [0.5974]\n",
            " [0.6255]\n",
            " [0.3371]\n",
            " [0.4947]\n",
            " [0.6103]\n",
            " [0.0215]\n",
            " [0.9721]\n",
            " [0.0673]\n",
            " [0.9185]\n",
            " [0.4949]\n",
            " [0.9234]\n",
            " [0.2649]\n",
            " [0.1416]\n",
            " [0.859 ]\n",
            " [0.7957]\n",
            " [0.8205]\n",
            " [0.7288]\n",
            " [0.0814]\n",
            " [0.4766]\n",
            " [0.4722]\n",
            " [0.5025]\n",
            " [0.8429]\n",
            " [0.6877]\n",
            " [0.6289]\n",
            " [0.6142]\n",
            " [0.5539]\n",
            " [0.6369]\n",
            " [0.3578]\n",
            " [0.801 ]\n",
            " [0.8716]\n",
            " [0.1818]\n",
            " [0.0914]\n",
            " [0.8511]\n",
            " [0.7166]\n",
            " [0.3609]\n",
            " [0.0808]\n",
            " [0.3835]]\n"
          ]
        }
      ],
      "source": [
        "s = make_innat_opinions(n, c1)\n",
        "print(s)\n",
        "# #################### Import Sythetic Network Data\n",
        "# df = pd.read_csv (save_path+'data/Adjacency Matrix.csv', header=None)\n",
        "# G = np.array(df[df.columns[:]])\n",
        "# # print(G)\n",
        "# df1 = pd.read_csv(save_path+'data/Innate Opinion.csv', header = None)\n",
        "# s = np.array(df1[df1.columns[:]])\n",
        "# # print(s)\n",
        "# # print(G.shape)\n",
        "\n",
        "# # Set n according to the data\n",
        "# n = len(s[:])\n",
        "# print(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV9KGKMnAO2u"
      },
      "outputs": [],
      "source": [
        "# G = creat_network(n)\n",
        "# s = make_innat_opinion(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GQ9aXQXZAO2u"
      },
      "outputs": [],
      "source": [
        "################## Process the Network Data\n",
        "L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
        "A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
        "m = num_edges(L, n)                    # call the function to calculate the number of edges\n",
        "# what the twitter graph looks like \n",
        "nxG = nx.from_numpy_matrix(G)          \n",
        "#plt.figure(figsize=(20, 20))\n",
        "# nx.draw(nxG)\n",
        "columnsum_ij = np.sum(A, axis=0)\n",
        "# print(columnsum_ij)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITpFRQgzAO2u"
      },
      "source": [
        "### 2. Equilibrium & Polarization \n",
        "$$P(z) = z ^T * z $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NMIW06RpAO2v"
      },
      "outputs": [],
      "source": [
        "# op = s\n",
        "# y = mean_center(s,n)\n",
        "# # print(y)\n",
        "# innat_pol = np.dot(np.transpose(y), y)[0,0] \n",
        "# print('Innate_polarization:')\n",
        "# print(innat_pol)\n",
        "\n",
        "# # Test equilibrium polarization\n",
        "# equ_pol = obj_polarization(A, L, s, n)\n",
        "# print('Equi_polarization:')\n",
        "# print(equ_pol)\n",
        "\n",
        "# di = equ_pol-innat_pol\n",
        "# print(\"Difference:\")\n",
        "# print(di)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NZm9FywAO2v"
      },
      "source": [
        "### 3. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "56bA_9OmAO2v"
      },
      "outputs": [],
      "source": [
        "def k_random_play(s,n,k):  # player randomly choose an agent and randomly change the agent\n",
        "    \n",
        "    op = copy.copy(s)\n",
        "    \n",
        "    ########### create all combination of K nodes\n",
        "    k_opinions = creat_all_comb(n, k)\n",
        "    len_nodesets = comb(n,k)\n",
        "\n",
        "    i_th = random.randint(0,len_nodesets-1)  # randomly select an agent index\n",
        "#     v_list = node_sets[v_index]\n",
        "    v_list = cgen(i_th,n,k)\n",
        "    \n",
        "    ########### create all combination of K opinions\n",
        "    len_kops = len(k_opinions) # - number of combinations exist\n",
        "    op_index = random.randint(0,len_kops-1) # randomly select index for an OPINION list \n",
        "    new_op = k_opinions[op_index]  # randomly select an opininon list(0 and 1) to update the opinion array\n",
        "#     print('Nodes, opinions')\n",
        "#     print(v_list,new_op)\n",
        "#     print(new_op)\n",
        "    op = change_k_innate_opinion(s, v_list, new_op)\n",
        "\n",
        "   # print(\"    \"+\"Agent\" + str(v) +\" 's opinion \" + str(old_opinion) + \" changed to \"+ str(new_op))\n",
        "    \n",
        "    por = obj_polarization(A, L, op, n)\n",
        "    \n",
        "    column = len_kops*i_th + op_index\n",
        "#     print(\"Network reaches stead_state Polarization: \" + str(por))\n",
        "\n",
        "    return (v_list, new_op, por, column)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cSAvYI_ZAO2v"
      },
      "outputs": [],
      "source": [
        "def k_random_play_1(s,n,k,max_touched):  # player randomly choose an agent and randomly change the agent\n",
        "    \n",
        "    op = copy.copy(s)\n",
        "#     max_opi_option = random.uniform(0, 1)   # options that maximizer have\n",
        "\n",
        "    a = len(set(max_touched))  # number of unqiue touched nodes\n",
        "    len_nodesets = comb(n-a,k) #  number of available combination of k nodes\n",
        "    \n",
        "    i_th = random.randint(0,len_nodesets-1)  # randomly select an action index\n",
        "    v_list = creat_available_comb(i_th, n,k,max_touched)\n",
        "  \n",
        "    new_op_list = []\n",
        "    for i in range(k):\n",
        "        #new_op = random.uniform(0, 1)  # randomly select an opininon between 0 and 1\n",
        "        new_op = 0.5\n",
        "        new_op_list.append(new_op)\n",
        "   \n",
        "    new_op_list = tuple(new_op_list)\n",
        "#     print('Nodes, opinions')\n",
        "#     print(v_list,new_op_list)\n",
        "    op = change_k_innate_opinion(s, v_list, new_op_list)\n",
        "   # print(\"    \"+\"Agent\" + str(v) +\" 's opinion \" + str(old_opinion) + \" changed to \"+ str(new_op))\n",
        "    por = obj_polarization(A, L, op, n)\n",
        "#     print(\"Network reaches steady-state Polarization: \" + str(por))\n",
        "#     print('Should be restored')\n",
        "#     print(op)\n",
        "    return (v_list, new_op_list, por)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTqB0BfgAO2v"
      },
      "outputs": [],
      "source": [
        "# k = 2\n",
        "# max_touched = [1,2]\n",
        "# (v, new_op_list, por) =k_random_play_1(s,n,k,max_touched)\n",
        "# print(v, new_op_list, por)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOKh2AQDAO2v"
      },
      "outputs": [],
      "source": [
        "# max_touched = [0]\n",
        "# v2 = [0]\n",
        "# k = 2\n",
        "# node_set = [1,2]\n",
        "# k_opinion = [0,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sVp1ReiAO2w"
      },
      "source": [
        "### Mixed Strategy Payoff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3qWjDcUyAO2w"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=3)\n",
        "def make_k_payoff_row(op1, h, v2): #op1 here is only changed by Min\n",
        "    payoff_row = np.zeros(h)\n",
        "    \n",
        "    column = 0 \n",
        "    i = 1\n",
        "    for i in range(0, comb(n,k)):# i - which set of nodes option \n",
        "#         print('nodeset'+ str(i))\n",
        "        nodes = cgen(i,n,k)\n",
        "#         print(nodes)\n",
        "        k_opinions = creat_all_comb(n, k)\n",
        "\n",
        "        for ops in k_opinions: # tuple index - select one combinatio of opinions\n",
        "#             print('opset'+ str(j))\n",
        "#             j = j + 1\n",
        "            op2 = change_k_innate_opinion(op1, nodes, ops) # op2 has changed by both min and max now\n",
        "            check =  any(node in nodes for node in v2)     \n",
        "            \n",
        " # when v1 == v2, the polarization should be negative for max, infinet for min. \n",
        " # Replace the the column_index of agent v2 with 0 for max                   \n",
        "            if check is False:    #if v1 != v2\n",
        "                # calculate the payofflarization\n",
        "                payoff = obj_polarization(A, L, op2, n) # calculate the payofflarization\n",
        "                payoff_row[column] = payoff\n",
        "                column = column + 1  \n",
        "#                 print(payoff_row) \n",
        "            else:                #if v1 == v2   \n",
        "                payoff_row[column] = 10000  # use to avoid min and max choose the same agent\n",
        "                column = column + 1  \n",
        "#                 print(payoff_row)   \n",
        "            \n",
        "#     print(payoff_row)        \n",
        "\n",
        "\n",
        "    return payoff_row    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6hsYTJGAO2w"
      },
      "outputs": [],
      "source": [
        "# h =  len_actions(k, n)\n",
        "# print(h)\n",
        "# v2 = (1,2)\n",
        "# payoff_row = make_k_payoff_row(s, h, v2)\n",
        "\n",
        "# print(payoff_row)\n",
        "# # print(len(s))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh_aPh3DAO2w"
      },
      "source": [
        "### Minimizer Mixed Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z7CbW71hAO2w"
      },
      "outputs": [],
      "source": [
        "# Calculate polarization of minimizer's Mixed Strategy\n",
        "def mixed_K_min_polarization(s,v2,k_opinion,fla_max_fre):\n",
        "\n",
        "    op1 = change_k_innate_opinion(s, v2, k_opinion) # only updated by minimizer's current change\n",
        "    # calculate the polarization with both min(did above) and max's action(in make_payoff_row)\n",
        "    payoff_row = make_k_payoff_row(op1, h, v2)  # the vector list out 2*n payoffs after min's action combine with 2*n possible max's actions\n",
        "#     print('payoff_row')\n",
        "#     print(payoff_row)\n",
        "    #calculate fictitious payoff - equi_min  \n",
        "    payoff_cal = payoff_row * fla_max_fre # fla_max_fre recorded the frequency of each maximizer's action, frequency sum = 1\n",
        "                                             # payoff (2*n array) * maximizer_action_frequency (2*n array)\n",
        "    # print('payoff_cal')\n",
        "    # print(payoff_cal)\n",
        "    mixed_pol = np.sum(payoff_cal) # add up all, calculate average/expected payoff\n",
        "#     print('Mixed_pol')\n",
        "#     print(mixed_pol)\n",
        "\n",
        "    # Replace the the column_index of agent v2 with -100 for max\n",
        "\n",
        "    payoff_row = [-10000 if ele == 10000 else ele for ele in payoff_row]\n",
        "\n",
        "\n",
        "    return (mixed_pol,payoff_row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VeF0sy0yAO2w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb4071de-426e-4ea9-9574-4b0ff93c5b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.607]\n",
            " [0.   ]\n",
            " [1.   ]\n",
            " [0.893]\n",
            " [0.982]\n",
            " [0.214]\n",
            " [0.783]\n",
            " [0.381]\n",
            " [0.8  ]\n",
            " [0.767]\n",
            " [0.3  ]\n",
            " [0.577]\n",
            " [0.624]\n",
            " [0.004]\n",
            " [0.553]\n",
            " [0.431]\n",
            " [0.925]\n",
            " [0.739]\n",
            " [0.988]\n",
            " [0.006]\n",
            " [0.229]\n",
            " [0.444]\n",
            " [0.305]\n",
            " [0.66 ]\n",
            " [0.926]\n",
            " [0.659]\n",
            " [0.673]\n",
            " [0.546]\n",
            " [0.456]\n",
            " [0.088]\n",
            " [0.684]\n",
            " [0.334]\n",
            " [0.903]\n",
            " [0.163]\n",
            " [0.71 ]\n",
            " [0.868]\n",
            " [0.71 ]\n",
            " [0.648]\n",
            " [0.66 ]\n",
            " [0.34 ]\n",
            " [0.953]\n",
            " [0.868]\n",
            " [0.97 ]\n",
            " [0.355]\n",
            " [0.264]\n",
            " [0.675]\n",
            " [0.289]\n",
            " [0.057]\n",
            " [0.813]\n",
            " [0.261]\n",
            " [0.482]\n",
            " [0.651]\n",
            " [0.29 ]\n",
            " [0.667]\n",
            " [0.808]\n",
            " [0.179]\n",
            " [0.718]\n",
            " [0.453]\n",
            " [0.728]\n",
            " [0.003]\n",
            " [0.231]\n",
            " [0.151]\n",
            " [0.649]\n",
            " [0.597]\n",
            " [0.626]\n",
            " [0.337]\n",
            " [0.495]\n",
            " [0.61 ]\n",
            " [0.021]\n",
            " [0.972]\n",
            " [0.067]\n",
            " [0.918]\n",
            " [0.495]\n",
            " [0.923]\n",
            " [0.265]\n",
            " [0.142]\n",
            " [0.859]\n",
            " [0.796]\n",
            " [0.821]\n",
            " [0.729]\n",
            " [0.081]\n",
            " [0.477]\n",
            " [0.472]\n",
            " [0.503]\n",
            " [0.843]\n",
            " [0.688]\n",
            " [0.629]\n",
            " [0.614]\n",
            " [0.554]\n",
            " [0.637]\n",
            " [0.358]\n",
            " [0.801]\n",
            " [0.872]\n",
            " [0.182]\n",
            " [0.091]\n",
            " [0.851]\n",
            " [0.717]\n",
            " [0.361]\n",
            " [0.081]\n",
            " [0.383]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6d24ceca96c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmixed_K_min_polarization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk_opinion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfla_max_fre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fla_max_fre' is not defined"
          ]
        }
      ],
      "source": [
        "node_set = [1,2]\n",
        "k_opinion = [0,1]\n",
        "op = change_k_innate_opinion(s, node_set, k_opinion)\n",
        "print(op)\n",
        "v2 = [3,4]\n",
        "a= mixed_K_min_polarization(s,v2,k_opinion,fla_max_fre)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qnKaZUPsAO2w"
      },
      "outputs": [],
      "source": [
        "############################################ k Min_opinion - Python Package Solve  ################################\n",
        "# k = 2\n",
        "# v2=[1,2]\n",
        "\n",
        "\n",
        "############## Create the sum_term - exclude selected nodes \n",
        "#M_1= sum_term - term_out    # numerator\n",
        "def sum_rest(n, op, v2):\n",
        "    # Reshape opinion array\n",
        "    op = np.reshape(op, (n,1))\n",
        "    \n",
        "    E_new =np.array([1/n] * n *n)  \n",
        "    E_new = np.reshape(E_new, (n,n)) # create a n*n matrix with all elements 1\n",
        "    #A_new = np.reshape(A, (n,n))\n",
        "    A_new = copy.copy(A)\n",
        "    A_temp=A_new-E_new\n",
        "    M_new_temp=A_temp@op\n",
        "    def sumFunction(x):\n",
        "        s_i = op[x]*A_temp[x]\n",
        "        return s_i\n",
        "    np.sum(A, axis=0)   \n",
        "    Out_term = np.sum([sumFunction(x) for x in v2],axis=0)  \n",
        "    Out_term = np.reshape(Out_term, (n,1))\n",
        "    M_rest = np.transpose(M_new_temp-Out_term)\n",
        "#     print('M')\n",
        "#     print(M_rest)\n",
        "    return M_rest\n",
        "\n",
        "############## Derivate min_opinions - using above result#####################################\n",
        "def k_derivate_s(v2,k,n,M): \n",
        "        # k - # of selected nodes\n",
        "        # V2 - selection list(k nodes) of minimier\n",
        "         #  take the node index from selection list\n",
        "         #  it's also the column index for these two nodes\n",
        "        # op - n*1 innate opinion array that updated by maximizer\n",
        "        # A - n*n adjacency matrix \n",
        "\n",
        "    # create a parameter array with all 1/n \n",
        "    c =np.array([1/n] * n)   \n",
        "    #c = np.reshape(c, (n,1))\n",
        "\n",
        "    ############## Create left side of '=' matrix\n",
        "    def leftFunction(x,y):\n",
        "        a_i = np.transpose(A[x]-c)@(A[y]-c)\n",
        "        return [a_i]\n",
        "    a = np.concatenate([leftFunction(x,y) for y in v2 for x in v2]) \n",
        "    a = np.reshape(a, (k,k))\n",
        "#     print('a')\n",
        "#     print(a)\n",
        "    ############ Create right side of '=' matrix\n",
        "    def rightFunction(x, M):\n",
        "        Mi = np.dot(M, (A[x]-c))\n",
        "        return -Mi  \n",
        "    b = np.concatenate([rightFunction(x,M) for x in v2])   \n",
        "#     print('b')\n",
        "#     print(b)\n",
        "    result = np.linalg.solve(a, b)\n",
        "#     print(a,b)   \n",
        "    return result\n",
        "\n",
        "\n",
        "# %run Check_Derivation_of_Two_Opinions.ipynb\n",
        "# M_1 = sum_rest(n, s, v2)\n",
        "\n",
        "# print('Testing sample - 3 results should be the same:')\n",
        "# result = k_derivate_s(v2,k,n,M_1)\n",
        "# print('result')\n",
        "# print(result)\n",
        "    \n",
        "# print('check result')\n",
        "# (x,y) = py_pack(A, s, n, v2)\n",
        "# (si,sl) = deriv_sty(A, s, n, v2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for multi-processing\n",
        "class Result:\n",
        "    def __init__(self,index,weight_op,payoff_row,mixed_por):\n",
        "        self.weight_op=weight_op\n",
        "        self.payoff_row=payoff_row\n",
        "        self.mixed_por= mixed_por\n",
        "        self.index=index\n",
        "       \n",
        "\n",
        "def identifyMin(res, allResult):\n",
        "    #print(allResult)\n",
        "    min_por = res[3]\n",
        "    # print('min_por')\n",
        "    # print(min_por)\n",
        "    min_res = min(allResult,key=itemgetter(3))\n",
        "    if min_res[3] < min_por:\n",
        "      min_por = min_res[3]\n",
        "      res = min_res      \n",
        "    return res"
      ],
      "metadata": {
        "id": "-6tVGIOjG1kA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1ys7oMmiAO2x"
      },
      "outputs": [],
      "source": [
        "def min_k_mixed_opinion(queue, s, n, len_nodesets, i_th, max_touched, fla_max_fre):\n",
        "\n",
        "    if i_th >= len_nodesets:# the forloop give n, which we take maximum (n-1)\n",
        "      i_th = len_nodesets - 1\n",
        "    v2 = creat_available_comb(i_th, n,k,max_touched)\n",
        "    # print('i_th',i_th,'v2',v2)\n",
        "\n",
        "    weight_op = 0\n",
        "    weight_M = 0\n",
        "    # loop for each max_action(in total 2*n) \n",
        "    k_opinions = creat_all_comb(n, k)\n",
        "    len_kops = len(k_opinions)\n",
        "\n",
        "    for column in range(h):\n",
        "        # print(column)\n",
        "        if fla_max_fre[column] !=0:\n",
        "            # print('column'+ str(column))\n",
        "#             print('Probability')\n",
        "#             print(round(fla_max_fre[column],3))\n",
        "            if column > k:\n",
        "                nodeset_index = int(column/len_kops)\n",
        "                opset_index = column%len_kops\n",
        "#                 print(\"nodeset_index, opset_index\")\n",
        "#                 print(nodeset_index, opset_index)\n",
        "            else:\n",
        "#                 print('less than 1')\n",
        "                nodeset_index = 0\n",
        "                opset_index = column\n",
        "#                 print(\"nodeset_index, opset_index\")\n",
        "#                 print(nodeset_index, opset_index)\n",
        "                \n",
        "            # Calculating Max's action at this column\n",
        "            v1 = cgen(nodeset_index,n,k)\n",
        "            max_opinion = k_opinions[opset_index] \n",
        "#             print('v1,max_opinion')\n",
        "#             print(v1,max_opinion)\n",
        "            op1 = change_k_innate_opinion(s, v1, max_opinion) # change innate opinion by max action\n",
        "#             print('check if max update the opinion')\n",
        "#             print(op1)\n",
        "   # Derivate optimal Min's opinion for nodeset v2\n",
        "            M_rest = sum_rest(n, op1, v2)  #{sum}{j}(s_j(h_j -c))  - rest of terms\n",
        "            weight_M = weight_M + fla_max_fre[column]*M_rest # {sum}{v} p_v * M\n",
        "#             print('M')\n",
        "#             print(M_rest)\n",
        "#     print('M_SUM')\n",
        "#     print(weight_M)\n",
        "    # Got optimal Min's opinion for v2\n",
        "    k_opinion = k_derivate_s(v2,k,n,weight_M) # give a set of k weighted opinions\n",
        "    (mixed_por, payoff_row) = mixed_K_min_polarization(s, v2, k_opinion,fla_max_fre)\n",
        "    \n",
        "#     print('Weighted polarization')\n",
        "#     print(mixed_por)\n",
        "    #res = Result(v2,k_opinion,payoff_row,mixed_por)\n",
        "    res = (v2,k_opinion,payoff_row,mixed_por)\n",
        "    if any(x < 0 for x in k_opinion):\n",
        "        print('Min_opinion less than 0') # min_opinion should be in the range (0,1)\n",
        "        print(k_opinion)\n",
        "        sys.exit()\n",
        "    \n",
        "    queue.put(res) ### added\n",
        "  # return(weight_op,payoff_row,mixed_por)  \n",
        "    return(res)    \n",
        "    #return(k_opinion,payoff_row,mixed_por)  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print('v1,max_opinion')\n",
        "# print(v1,max_opinion)\n",
        "fla_max_fre = np.zeros([1*h])\n",
        "fla_max_fre[2] = 0.1\n",
        "fla_max_fre[3] = 0.4\n",
        "fla_max_fre[7] = 0.5\n",
        "# print(fla_max_fre)\n",
        "v1 = [1,2]\n",
        "max_touched =[1,2]\n",
        "max_opinion = [0,1]\n",
        "\n",
        "a = len(set(max_touched))\n",
        "len_nodesets = comb(n-a,k)\n",
        "batch_size = multiprocessing.cpu_count()\n",
        "op = change_k_innate_opinion(s, v1, max_opinion) \n",
        "min_por = obj_polarization(A, L, op, n)\n",
        "champion = (None, None, None,min_por)  # assume the best action is champion\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0, len_nodesets, batch_size):  \n",
        "    queue = Queue()\n",
        "    #for v2 in range(i, i+batch_size):\n",
        "      # print('fake v2')\n",
        "      # print(v2)\n",
        "    print(i)\n",
        "    print(\"-------------------------\")\n",
        "    processes = [Process(target=min_k_mixed_opinion, args=(queue, s, n, len_nodesets, i_th, max_touched, fla_max_fre,)) for i_th in range(i, i+batch_size)]\n",
        "      #result = min_mixed_opinion(queue, s, n, v2, max_touched, fla_max_fre)\n",
        "#       print('result')\n",
        "#       print(result)\n",
        "    for process in processes:\n",
        "        process.start()\n",
        "        #wait for all processes to complete:\n",
        "    for process in processes:\n",
        "        process.join()\n",
        "    results = [queue.get() for _ in processes]\n",
        "    champion = identifyMin(champion, results)\n",
        "    # all_results.append(results)\n",
        "\n",
        "    # print('results')\n",
        "    # print(results)\n",
        "print(\"champion\",champion)\n",
        "#print(all_results)\n",
        "# print('_________________________')\n",
        "#champion = identifyMin_test(20, all_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zwQfxdB4M_4W",
        "outputId": "acebc3a3-cf8e-47c5-8e04-088cf08e3d31"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "-------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process Process-2:\n",
            "Process Process-1:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4a0a7d9fb436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#wait for all processes to complete:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mchampion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifyMin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchampion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "gm0qcxjVAO2x"
      },
      "outputs": [],
      "source": [
        "# Minimizer search: Go through each agent \n",
        "\n",
        "def mixed_choose_min_vertex(s, n, v1, max_opinion, max_touched, fla_max_fre):\n",
        "    # current polarization that changed by maximizer, \"innate\" objective that min start with\n",
        "#     op = change_k_innate_opinion(s, v1, max_opinion) \n",
        "# #     print('Check if op has been updated by Maximizer')\n",
        "# #     print(op)\n",
        "#     min_por = obj_polarization(A, L, op, n) #min_por- set a standard to compare with pol after min's action\n",
        "# #     print('check maxup por')\n",
        "# #     print(min_por)\n",
        "# #     payoffs = []    # create an empty list to store all polarizations   \n",
        "#     champion = (None, None, None, min_por)  # assume the best action is champion\n",
        "\n",
        "#     queue = Queue()\n",
        "#     batch_size = multiprocessing.cpu_count()\n",
        "\n",
        "#     a = len(set(max_touched))\n",
        "#     len_nodesets = comb(n-a,k)\n",
        "\n",
        "\n",
        "    a = len(set(max_touched))\n",
        "    len_nodesets = comb(n-a,k)\n",
        "    batch_size = multiprocessing.cpu_count()\n",
        "    op = change_k_innate_opinion(s, v1, max_opinion) \n",
        "    min_por = obj_polarization(A, L, op, n)\n",
        "    champion = (None, None, None,min_por)  # assume the best action is champion\n",
        "\n",
        "\n",
        "    \n",
        "    for i in range(0, len_nodesets, batch_size):  \n",
        "        queue = Queue()\n",
        "        processes = [Process(target=min_k_mixed_opinion, args=(queue, s, n, len_nodesets, i_th, max_touched, fla_max_fre,)) for i_th in range(i, i+batch_size)]\n",
        "\n",
        "        for process in processes:\n",
        "            process.start()\n",
        "            #wait for all processes to complete:\n",
        "        for process in processes:\n",
        "            process.join()\n",
        "        results = [queue.get() for _ in processes]\n",
        "        champion = identifyMin(champion, results)\n",
        "\n",
        "        # print('results')\n",
        "        # print(results)\n",
        "    #print(\"champion\",champion)\n",
        "              \n",
        "    return (champion)  # find the best minimizer's action after going through every new_op option of every agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzy2KbxwAO2x",
        "outputId": "a81c560c-c869-4eb2-e2e6-74e2246d69eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "champion ([3, 9], array([0.6564, 0.6553]), [0.6857993348146852, 0.622559542299511, 0.6394508913090888, 0.4705385764796225, 0.7434398902727444, 0.7620707262834341, 0.7251682830143482, 0.5607351886770302, -10000, -10000, -10000, -10000, 0.7914363653981396, 0.8184502420325162, 0.805442552103433, 0.7095650730253171, 0.7954946385460235, 0.7847393204098208, 0.7857418632309545, 0.645162285820954, 0.6983715146537637, 0.7331446462423507, 0.7269909678960882, 0.6584685807141023, 0.7852505055719265, 0.7837396925888839, 0.8019261867929331, 0.6939172274674633, 0.5817676535350788, 0.6907081509314578, 0.6820812163490777, 0.6235065377484305, -10000, -10000, -10000, -10000, 0.6444206349998178, 0.6099547502351526, 0.576644770656925, 0.37191492766929307, -10000, -10000, -10000, -10000, 0.7020746267709378, 0.6929120289658938, 0.6603395854943187, 0.5440500396187451, 0.6985077624771121, 0.6513784574191663, 0.6445604528760683, 0.4594333763470108, 0.6113188465572322, 0.6181696793931114, 0.6091615204463627, 0.4924906167158844, 0.6953482253049493, 0.6644799165982324, 0.6738043939494162, 0.5232545628393358, 0.5164047759691667, 0.5775591877327826, 0.568870515523292, 0.46343707415527674, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, 0.7541880376688391, 0.773152483024248, 0.8091221647378896, 0.6442165107718395, 0.758174589549079, 0.7345791684548975, 0.7699954866746942, 0.574256225690029, 0.6694866258363908, 0.6882558707737013, 0.7085425605779163, 0.6198381099588823, 0.7544899574935405, 0.7365168955365191, 0.78124729988021, 0.6522755872807483, 0.569674976618269, 0.6464988743926996, 0.6543569314167638, 0.5882965567783562, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, 0.795022562430146, 0.8378544304085014, 0.8397171011669553, 0.7019845536695674, 0.6942488029461464, 0.7564563801992589, 0.7703509066328721, 0.7162848462526694, 0.7587326450274947, 0.8239274609998694, 0.8674603459614216, 0.7435460854791999, 0.6089216072707028, 0.7077987337073203, 0.6750569689405657, 0.6836736321062862, -10000, -10000, -10000, -10000, 0.7046988197811808, 0.748291849907663, 0.7548528533877965, 0.6643221569237412, 0.7809004413065326, 0.8060606176343905, 0.8497162896528585, 0.6852460085809098, 0.606376195262631, 0.7031628067988367, 0.6783349162911831, 0.6348994915577171, -10000, -10000, -10000, -10000, 0.6543814288211917, 0.7444222790937232, 0.7597963779133161, 0.6879408081557858, 0.48163852774997734, 0.623303941372523, 0.5861735273870992, 0.6119879393674162, -10000, -10000, -10000, -10000, 0.5569383106986058, 0.7065076274226321, 0.6568741572510086, 0.6549934271941269, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000], 0.532528114061273)\n",
            "Finished in 0.6 second(s)\n"
          ]
        }
      ],
      "source": [
        "# print('v1,max_opinion')\n",
        "# print(v1,max_opinion)\n",
        "fla_max_fre = np.zeros([1*h])\n",
        "fla_max_fre[2] = 0.1\n",
        "fla_max_fre[3] = 0.4\n",
        "fla_max_fre[7] = 0.5\n",
        "# print(fla_max_fre)\n",
        "v1 = [1,2]\n",
        "max_touched =[1,2]\n",
        "max_opinion = [0,1]\n",
        "\n",
        "start = time.perf_counter()\n",
        "\n",
        "# protect the entry point\n",
        "if __name__ == '__main__':\n",
        "  mixed_choose_min_vertex(s, n, v1, max_opinion, max_touched, fla_max_fre)\n",
        "\n",
        "end = time.perf_counter()\n",
        "print(f'Finished in {round(end-start, 2)} second(s)') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97l-kQq-AO2x"
      },
      "outputs": [],
      "source": [
        "# v1= [1,2]\n",
        "# champion = mixed_choose_min_vertex(s, n, v1, max_opinion, max_touched, fla_max_fre)\n",
        "# print(champion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6HwiyndAO2x"
      },
      "outputs": [],
      "source": [
        "# (all_sets, k_opinions) = creat_all_comb(n, k)\n",
        "# print('all_sets,k_opinions')\n",
        "# print(all_sets,k_opinions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "JRs5bTn1AO2x"
      },
      "outputs": [],
      "source": [
        "####Op has been updated by maximizer, fla_max_fre includes max's hisotry, so minimizer react to the innate op after that\n",
        "def mixed_min_play(s,v1,max_opinion,n, max_touched,fla_max_fre): \n",
        "\n",
        "#     print('_______________________')\n",
        "#     print('Minimizer Play')\n",
        "#     print('Only 1 opinion changed')\n",
        "#     print(op)\n",
        "    \n",
        "    min_champion = mixed_choose_min_vertex(s, n, v1, max_opinion, max_touched, fla_max_fre)\n",
        "    (v2, min_opinion, payoff_row, min_pol) = min_champion\n",
        "    \n",
        "    if v2 == None:    # if minimizer cannot find a action to minimize polarization after maximizer's action\n",
        "        print('Minimizer fail')\n",
        "\n",
        "    else:\n",
        "#         print(\"                                \")\n",
        "        print(\"Minimizer finds its target agents:\")\n",
        "        print(v2)\n",
        "\n",
        "        # Store innate_op of the min_selected k vertex\n",
        "        old_opinion_min = [s[i] for i in v2]\n",
        "\n",
        "#         print(\"    \"+\"Agent\" + str(v2) +\" 's opinion \" + str(old_opinion_min) + \" changed to \"+ str(min_opinion))\n",
        "#         print('fla_max_fre')\n",
        "#         print(fla_max_fre[np.nonzero(fla_max_fre)])\n",
        "\n",
        "\n",
        "#         print(\"Payoff row\")\n",
        "#         print(payoff_row)\n",
        "#         print(\"Network reaches steady-state Polarization: \" + str(min_pol))\n",
        "\n",
        "    return (tuple(v2), payoff_row, min_opinion, min_pol)                 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "scrolled": false,
        "id": "1PWKNYESAO2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf84557b-d82b-4000-afec-5c404f23749b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimizer finds its target agents:\n",
            "[3, 9]\n"
          ]
        }
      ],
      "source": [
        "v2 = [1,2]\n",
        "# max_opinion=[1,1]\n",
        "# fla_max_fre = h*[0]\n",
        "(v2, payoff_row, min_opinion, min_pol) = mixed_min_play(s,v1,max_opinion,n, max_touched,fla_max_fre)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqg7vzUKAO2x"
      },
      "source": [
        "### Maximizer Mixed Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "0VQlqv_hAO2y"
      },
      "outputs": [],
      "source": [
        "####Op has been updated by minimizer, fla_min_fre includes min's hisotry, so maxmizer react to the innate op after that\n",
        "def k_max_polarization(payoff_matrix,column,fla_min_fre):\n",
        "\n",
        "    # create payoff matrix for maxmizer\n",
        "    payoff_vector = payoff_matrix[:,column]\n",
        "#     print('payoff_vector')\n",
        "#     print(payoff_vector)\n",
        "    if any(i> 10 for i in payoff_vector) >10:\n",
        "        print('Error in Payoff Matrix')\n",
        "        sys.exit\n",
        "    #calculate fictitious payoff - equi_max  \n",
        "#     print('fla_min_fre')\n",
        "#     print(fla_min_fre)\n",
        "    payoff_cal = payoff_vector * fla_min_fre #payoff * frequency\n",
        "\n",
        "    mixed_pol = np.sum(payoff_cal) # add up\n",
        "\n",
        "    return mixed_pol\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "M3eO-g_0AO2y"
      },
      "outputs": [],
      "source": [
        "# payoff_matrix = np.empty((1, h), float)\n",
        "# mixed_pol = k_max_polarization(payoff_matrix,column, fla_min_fre)\n",
        "# payoff_matrix[:,1]=10\n",
        "# print(payoff_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "v1lH3ZrzAO2y"
      },
      "outputs": [],
      "source": [
        "def find_idx(k_nodes,n):\n",
        "\n",
        "    latter=0\n",
        "    index = 0\n",
        "    k = len(k_nodes)\n",
        "    \n",
        "    for i in range(k):\n",
        "        before = k_nodes[i] + 1\n",
        "#         print('before')\n",
        "#         print(before)\n",
        "        L_min = latter + 1\n",
        "        L_max = before - 1\n",
        "\n",
        "        M = L_max - L_min\n",
        "\n",
        "        for m in range(1, M+2):\n",
        "            P = n - latter - m\n",
        "            L = k -1 - i\n",
        "            index = index + comb(P,L)\n",
        "        latter = before\n",
        "        \n",
        "    return index\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "iPiwPKgPAO2y"
      },
      "outputs": [],
      "source": [
        "# n = 100\n",
        "# k_nodes=cgen(123,n,4)\n",
        "# a = test_1(k_nodes,n)\n",
        "# print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "LjtmdAFSAO2y"
      },
      "outputs": [],
      "source": [
        "# # pass on the innate opinion that has been changed by minimizer\n",
        "def max_k_play(payoff_matrix, op, n, k, fla_min_fre, min_touched): # - op1 - innate opinion that has been changed by minimizer\n",
        "    k_opinions = creat_all_comb(n, k)\n",
        "    len_kops = len(k_opinions)\n",
        "    \n",
        "    ############ start producing changes ###########\n",
        "    count = 0\n",
        "    all_por = np.zeros(h)\n",
        "#     print('all_por')\n",
        "#     print(all_por)\n",
        "    \n",
        "    a = len(set(min_touched)) # number of unique touched agent\n",
        "    len_avsets = comb(n-a,k) # length of available k_nodes combinations\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i_th in range(len_avsets): # for each available k nodes\n",
        "#         print('_________________________________')\n",
        "#         print('Max start with'+ str(i_th) + '_th k nodes')\n",
        "        v1 = creat_available_comb(i_th, n,k,min_touched)  #for i in node_sets:  # for each available k nodes\n",
        "#         print(v1)\n",
        "#         print(i)\n",
        "#         k_nodes_index = all_sets.index(i) \n",
        "        k_nodes_index = find_idx(v1,n) # map this nodeset to its index located in all lists\n",
        "        \n",
        "        for f in range(len_kops):         # for each opinion combination \n",
        "            column = k_nodes_index*len_kops + f  # locate the column in payoff row- all combinations\n",
        "            #por = obj_polarization(A, L, s, n)\n",
        "            por= k_max_polarization(payoff_matrix, column, fla_min_fre) # calculate mixed polarization\n",
        "            all_por[column] = por\n",
        "\n",
        "    # ############# best action ##########\n",
        "#     print('all_por')\n",
        "#     print(all_por)\n",
        "    column = np.argmax(all_por) # Index of maximum polarization - in all actions\n",
        "#     print('column - best action')\n",
        "#     print(column)\n",
        "\n",
        "    \n",
        "    (v1, max_opinion) = map_action(n,k,column)\n",
        "#     print('v1,max_opinion')\n",
        "#     print(v1,max_opinion)\n",
        "    # print(all_sets)\n",
        "\n",
        "    # # Find innate opinion of k nodes - Comment - testing use\n",
        "    # old_opinion_max = [s[i] for i in v1]\n",
        "    print(\"                                \")\n",
        "    print(\"Maximizer finds its target \"+str(k)+ \" agent:\")\n",
        "    print(str(v1) + \"  op:\" + str(max_opinion))\n",
        "\n",
        "    ## check if agent's opinionis is changed or not\n",
        "#     print(\"    \"+\"Agent\" + str(v1) +\" 's opinion \" + str(old_opinion_max) + \" changed to \"+ str(max_opinion))\n",
        "#     print(\"Network reaches steady-state Polarization: \" + str(np.max(all_por)))\n",
        "\n",
        "    return(v1, max_opinion, np.max(all_por), column)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "aForUf7yAO2y"
      },
      "outputs": [],
      "source": [
        "# # print(payoff_matrix)\n",
        "# # payoff_matrix.shape\n",
        "# # fla_min_fre = h*[1]\n",
        "\n",
        "# min_touched = [0,1]\n",
        "\n",
        "# a = max_k_play(payoff_matrix, s, n, k, fla_min_fre, min_touched)\n",
        "# print('v1, max_opinion, np.max(all_por), column')\n",
        "# print(a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "eDOVJ_AFAO2y"
      },
      "outputs": [],
      "source": [
        "# column = 286\n",
        "# map_action(n,k,column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDCCOOocAO2y"
      },
      "source": [
        "## 5. Innate Op and Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vJ5dHnSAO2y"
      },
      "source": [
        "# Fictitious Play Start !\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVeX6DlYAO2y"
      },
      "outputs": [],
      "source": [
        "# op = s\n",
        "# y = mean_center(s,n)\n",
        "# # print(y)\n",
        "# innat_pol = np.dot(np.transpose(y), y)[0,0] \n",
        "# print('Innate_polarization:')\n",
        "# print(innat_pol)\n",
        "\n",
        "# # Test equilibrium polarization\n",
        "# equ_pol = obj_polarization(A, L, op, n)\n",
        "# print('Equi_polarization:')\n",
        "# print(equ_pol)\n",
        "\n",
        "# di = equ_pol-innat_pol\n",
        "# print(\"Difference:\")\n",
        "# print(di)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "IDxfF449AO2y"
      },
      "outputs": [],
      "source": [
        "# # Game Parameters\n",
        "# Game_rounds =200 # Rounds + 1- use for printing data\n",
        "# memory = 50\n",
        "\n",
        "# Game Preparation\n",
        "def push(obj, element):\n",
        "    if len(obj) >= memory:\n",
        "        dif = len(obj) - memory\n",
        "        obj.pop(dif)\n",
        "    obj.extend(list(element))\n",
        "    obj = list(set(obj))\n",
        "    \n",
        "    return obj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "-rMtPl9AAO2z"
      },
      "outputs": [],
      "source": [
        "def map_action(n,k,column):\n",
        "\n",
        "    k_opinions = creat_all_comb(n, k)\n",
        "    len_kops = len(k_opinions)\n",
        "    nodeset_index = int(column/len_kops) \n",
        "    opset_index = column%len_kops\n",
        "    k_nodes = cgen(nodeset_index, n, k)\n",
        "    opinions = k_opinions[opset_index]\n",
        "    \n",
        "    return (k_nodes, opinions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "pjZ5xSLoAO2z"
      },
      "outputs": [],
      "source": [
        "def excute(h, k, Game_rounds):\n",
        "# Preparation for the game\n",
        "    op = copy.copy(s)\n",
        "    payoff_matrix = np.empty((0, h), float)\n",
        "    max_history = np.zeros(h, int)  # n*2 matrix, agent i & opinion options\n",
        "    min_history = []  # append a list of (agent i, min_opinion), min_opinion can be any value\n",
        "    #     print(type(min_history))\n",
        "\n",
        "    max_history_last_100 = np.zeros(h, int) \n",
        "    min_history_last_100= []\n",
        "\n",
        "    max_touched = []\n",
        "    min_touched = []\n",
        "    min_touched_all = []\n",
        "    min_touched_last_100 =[]\n",
        "\n",
        "\n",
        "    # Game start from maximizer random play\n",
        "    #     print('Maximizer first selection')\n",
        "    (v1, max_opinion, max_pol, column) = k_random_play(s,n,k)\n",
        "    #(v1, max_opinion, max_pol) = random_play(op,n)   # Maximizer does random action \n",
        "    #(v1, max_opinion, max_pol) = maximizer_fir_play(s,n,min_touched)\n",
        "\n",
        "    First_max = (v1, max_opinion, max_pol) \n",
        "\n",
        "    # Maximizer start with greedy play\n",
        "    # (v1, max_opinion, max_pol) = maximizer_fir_play(s,n,min_touched)   # Maximizer choose action greedily\n",
        "\n",
        "    max_touched.extend(tuple(v1))\n",
        "    #     print('max_touched')\n",
        "    #     print(max_touched)\n",
        "    # store maximizer play history, using agent(row) and changed opinion(column) as indicator to locate history\n",
        " ####### max_history[column] = max_history[column] +1\n",
        "    # print('max_history')\n",
        "    # print(max_history)\n",
        "    #     print('history at spot')\n",
        "    #     print(max_history[column])\n",
        "\n",
        "    fla_max_fre = max_history/1  # its frequency, only played  1 time so far, divided by 1 \n",
        "\n",
        "    #     print('fla_max_fre')\n",
        "    #     print(fla_max_fre)\n",
        "    #fla_max_fre = max_frequency.flatten()   # flatten the n*2 matrix to a 2n*1 matrix\n",
        "                                            # so we can multiply the freuency (2n*1)with payoff array (1*2n) \n",
        "                                            # to get average payoff of fictitious play\n",
        "\n",
        "    # if game start from minimizer random play - make sure two random play are not same agent!!!\n",
        "    #     print('Minimizer first selection')\n",
        "    (v2, min_opinion, min_pol) = k_random_play_1(s,n,k,max_touched)\n",
        "    #(v2, min_opinion, min_pol) = minimizer_fir_play(s,n,min_touched)\n",
        "\n",
        "    First_min = (v2, min_opinion, min_pol)\n",
        "\n",
        "    if any(x in v1 for x in v2): # if Max and Min randomly selected the same agent, then we need to restart - cannot choose same agent\n",
        "        sys.exit()\n",
        "\n",
        "    # Minimizer start with greedy play\n",
        "    # (v2, min_opinion, min_pol) = minimizer_fir_play(s,n,max_touched)\n",
        "#####min_touched.extend(v2)\n",
        "#####min_touched_all.append(tuple(v2)) \n",
        "    # store minimizer play history\n",
        "######    min_history.append((tuple(v2)+ min_opinion))\n",
        "    #     print('min_history')\n",
        "    #     print(min_history)\n",
        "\n",
        "    counter=collections.Counter(min_history)  #return a dictionary include {'min_option': count of this choice}\n",
        "    #     print(counter)\n",
        "    fla_min_fre = np.array(list(counter.values()))/1 #return only frequency of all min options in order\n",
        "    #     print('fla_min_fre')\n",
        "    #     print(fla_min_fre)\n",
        "\n",
        "    #     (mixed_pol,payoff_row)\n",
        "\n",
        "    (a,payoff_row) = mixed_K_min_polarization(s, v2, min_opinion,fla_max_fre)\n",
        "    # print('payoff_row')\n",
        "    # print(payoff_row)\n",
        "    #payoff_matrix = np.vstack([payoff_matrix, payoff_row])\n",
        "    #     print('Payoff Matrix')\n",
        "    #     print(payoff_matrix)\n",
        "#####min_counter = dict(counter)\n",
        "    #     print('fla_min_fre at the spot')\n",
        "    #     print(min_counter)\n",
        "    #     print(min_counter[(v2+min_opinion)]) \n",
        "    #     print(min_counter[(v2,min_opinion)]/(i+1)) #get the value from dictionary by using key (v2,opinion)\n",
        "    equi_min = min_pol\n",
        "    equi_max = max_pol\n",
        "    # print(equi_min)\n",
        "    # print(equi_max)\n",
        "\n",
        "\n",
        "    Flag = 0\n",
        "\n",
        "    i = 0\n",
        "    while Flag == 0: \n",
        "        i = i + 1\n",
        "        print(\"Game \" + str(i))\n",
        "        print(\"_____________________\")\n",
        "\n",
        "    #     if max_pol == min_pol:\n",
        "        if i == Game_rounds:            # i == # of iterations you want to run + 2\n",
        "                                # because Game 101 is skipped for collecting data, to get 200 game result, we need to run 201 iteration\n",
        "            print('MAX_last_100,  all')  \n",
        "            max_l100_fre = max_history_last_100/100\n",
        "            max_fre = max_history/Game_rounds\n",
        "            print(max_l100_fre [np.nonzero(max_l100_fre)], max_fre[np.nonzero(max_fre)])\n",
        "            print(np.nonzero(max_l100_fre)[0], np.nonzero(max_fre)[0])\n",
        "            columns = list(np.nonzero(max_l100_fre)[0])\n",
        "            for column in list(columns):\n",
        "                    k_opinions = creat_all_comb(n, k)\n",
        "                    len_kops = len(k_opinions)\n",
        "                    nodeset_index = int(column/len_kops) \n",
        "                    opset_index = column%len_kops\n",
        "                    k_nodes = cgen(nodeset_index, n, k)\n",
        "\n",
        "                    opinions = k_opinions[opset_index]\n",
        "                    print('Max Nodes:'+ str(k_nodes)+' Opinion: '+ str(opinions))\n",
        "\n",
        "\n",
        "\n",
        "            # MINimizer's Strategy in the last 100 round\n",
        "            counter=collections.Counter(min_touched_last_100)\n",
        "            fla_min_fre = np.array(list(counter.values()))/(100) #return only frequency of all min options in order\n",
        "            print('MIN_last_100,  all')\n",
        "            counter_1=collections.Counter(min_touched_all)  #return a dictionary include {'min_option': count of this choice}\n",
        "            fla_min_fre_1 = np.array(list(counter_1.values()))/Game_rounds #return only frequency of all min options in order\n",
        "            print(fla_min_fre, fla_min_fre_1)\n",
        "            print(counter, counter_1)\n",
        "            print('Max Pol: '+str(equi_max)+\"  Min Pol: \"+str(equi_min))\n",
        "\n",
        "            break\n",
        "\n",
        "        elif equi_min == equi_max:\n",
        "            print(\"Reached Nash Equilibrium at game\"+ str(i) + \"and Equi_Por = \" + str(equi_min))\n",
        "    #             print('max_distribution')\n",
        "    #             print(max_frequency)\n",
        "    #             print('min_distribution')\n",
        "    #             print(fla_min_fre)\n",
        "            Flag = 1\n",
        "            break\n",
        "    #________________________________________________________________\n",
        "        ############################## maximizer play  \n",
        "        else:\n",
        "            if i == Game_rounds-100:    #if Game_round = 200, after 100 iteration, Game 101 print previous historical result\n",
        "\n",
        "            # Remove max frequncy less than 0.1--\n",
        "                max_history_last_100 = np.zeros(h) \n",
        "                min_history_last_100 = [] \n",
        "                min_touched_last_100 =[]\n",
        "\n",
        "            (v1, max_opinion, equi_max, column) = max_k_play(payoff_matrix, op, n, k, fla_min_fre, min_touched)\n",
        "            #(v1, max_opinion, equi_max) = mixed_max_play(payoff_matrix,s,v2,min_opinion,n,min_touched,fla_min_fre)\n",
        "            max_touched = push(max_touched, v1)\n",
        "            #max_touched.extend(list(v1))\n",
        "    #             print('max_touched')\n",
        "    #             print(max_touched)\n",
        "\n",
        "            # cumulate strategy \n",
        "            max_history[column] = max_history[column] +1\n",
        "\n",
        "            max_history_last_100[column] = max_history_last_100[column] +1\n",
        "    #         print('max_history')\n",
        "    #         print(max_history)\n",
        "            fla_max_fre = max_history/(i+1)  # max_frequency to calculate average payoff\n",
        "            print('fla_max_fre')\n",
        "            print(fla_max_fre [np.nonzero(fla_max_fre)])\n",
        "    #             print('fre_max at spot')\n",
        "    #             print(fla_max_fre[column])\n",
        "    #         print(fla_max_fre)\n",
        "\n",
        "    #________________________________________________________________\n",
        "    ############################### MINImizer play\n",
        "            (v2, payoff_row, min_opinion, equi_min) = mixed_min_play(s,v1,max_opinion,n, max_touched,fla_max_fre)\n",
        "    #         print('v2')\n",
        "    #         print(v2)\n",
        "            min_touched = push(min_touched, v2)\n",
        "            min_touched_all.append(v2) \n",
        "            min_touched_last_100.append(v2)\n",
        "    #             print('min_touched')\n",
        "    #             print(min_touched)\n",
        "    #             print('min_touched_last_100')\n",
        "    #             print(min_touched_last_100)\n",
        "    #         print('equi_min')\n",
        "    #         print(equi_min)\n",
        "    #         print('max_touched')\n",
        "    #         print(max_touched)\n",
        "            #         print(v2, min_opinion, min_pol)\n",
        "            if tuple(tuple(v2)+min_opinion) in counter.keys():\n",
        "                payoff_matrix = payoff_matrix # if this min_option is in min_history, no need to update paryoff matrix, only update frequency\n",
        "    #                 print(\"Same history\")\n",
        "    #                 print((str(v2),str(min_opinion)))\n",
        "            else:\n",
        "                payoff_matrix = np.vstack([payoff_matrix, payoff_row]) # if this is a new option, append to previous matrix\n",
        "    #                 print('payoff_row')\n",
        "    #                 print(payoff_row)\n",
        "\n",
        "            min_history.append(tuple(v2 + min_opinion))  \n",
        "            min_history_last_100.append(tuple(v2 + min_opinion))\n",
        "    #             print('min_history')\n",
        "    #             print(min_history)\n",
        "            counter=collections.Counter(min_history)  #return a dictionary include {'min_option': count of this choice}\n",
        "            counter_1=collections.Counter(min_touched_all)  #return a dictionary include {'min_option': count of this choice}\n",
        "            fla_min_fre_1 = np.array(list(counter_1.values()))/Game_rounds #return only frequency of all min options in order\n",
        "            print('min_fre')\n",
        "            print(fla_min_fre_1)\n",
        "            print(counter_1)\n",
        "\n",
        "            # print(counter.keys())\n",
        "            fla_min_fre = np.array(list(counter.values()))/(i+1) #return only frequency of all min options in order\n",
        "            # print('fla_min_fre')\n",
        "            # print(fla_min_fre [np.nonzero(fla_min_fre)])\n",
        "    #             print(\"Not Reached Nash Equilibrium at Equi_Min = \" + str(equi_min) + \" and Equi_Max = \"+ str(equi_max)) \n",
        "\n",
        "    result = (First_max, First_min, max_touched, min_touched, payoff_matrix, min_history, fla_min_fre, min_history_last_100, min_touched_last_100, min_touched_all, max_history, fla_max_fre, max_history_last_100, equi_max, equi_min)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "M__tKVuYAO2z",
        "outputId": "22d9d25f-d804-4aaa-9c28-093f3b5811f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Game 1\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 1]  op:(0, 0)\n",
            "fla_max_fre\n",
            "[0.5]\n",
            "Minimizer finds its target agents:\n",
            "[7, 8]\n",
            "min_fre\n",
            "[0.005]\n",
            "Counter({(7, 8): 1})\n",
            "Game 2\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[3, 5]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.3333 0.3333]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.005]\n",
            "Counter({(7, 8): 1, (8, 9): 1})\n",
            "Game 3\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.25 0.25 0.25]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.01 ]\n",
            "Counter({(8, 9): 2, (7, 8): 1})\n",
            "Game 4\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.2 0.4 0.2]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.015]\n",
            "Counter({(8, 9): 3, (7, 8): 1})\n",
            "Game 5\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.1667 0.5    0.1667]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.02 ]\n",
            "Counter({(8, 9): 4, (7, 8): 1})\n",
            "Game 6\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.1429 0.5714 0.1429]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.025]\n",
            "Counter({(8, 9): 5, (7, 8): 1})\n",
            "Game 7\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.125 0.625 0.125]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.03 ]\n",
            "Counter({(8, 9): 6, (7, 8): 1})\n",
            "Game 8\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.1111 0.6667 0.1111]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.035]\n",
            "Counter({(8, 9): 7, (7, 8): 1})\n",
            "Game 9\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.1 0.7 0.1]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.04 ]\n",
            "Counter({(8, 9): 8, (7, 8): 1})\n",
            "Game 10\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0909 0.7273 0.0909]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.045]\n",
            "Counter({(8, 9): 9, (7, 8): 1})\n",
            "Game 11\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0833 0.75   0.0833]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.05 ]\n",
            "Counter({(8, 9): 10, (7, 8): 1})\n",
            "Game 12\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0769 0.7692 0.0769]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.055]\n",
            "Counter({(8, 9): 11, (7, 8): 1})\n",
            "Game 13\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0714 0.7857 0.0714]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.06 ]\n",
            "Counter({(8, 9): 12, (7, 8): 1})\n",
            "Game 14\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0667 0.8    0.0667]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.065]\n",
            "Counter({(8, 9): 13, (7, 8): 1})\n",
            "Game 15\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0625 0.8125 0.0625]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.07 ]\n",
            "Counter({(8, 9): 14, (7, 8): 1})\n",
            "Game 16\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0588 0.8235 0.0588]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.075]\n",
            "Counter({(8, 9): 15, (7, 8): 1})\n",
            "Game 17\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0556 0.8333 0.0556]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.08 ]\n",
            "Counter({(8, 9): 16, (7, 8): 1})\n",
            "Game 18\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0526 0.8421 0.0526]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.085]\n",
            "Counter({(8, 9): 17, (7, 8): 1})\n",
            "Game 19\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.05 0.85 0.05]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.09 ]\n",
            "Counter({(8, 9): 18, (7, 8): 1})\n",
            "Game 20\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0476 0.8571 0.0476]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.095]\n",
            "Counter({(8, 9): 19, (7, 8): 1})\n",
            "Game 21\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0455 0.8636 0.0455]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.1  ]\n",
            "Counter({(8, 9): 20, (7, 8): 1})\n",
            "Game 22\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0435 0.8696 0.0435]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.105]\n",
            "Counter({(8, 9): 21, (7, 8): 1})\n",
            "Game 23\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0417 0.875  0.0417]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.11 ]\n",
            "Counter({(8, 9): 22, (7, 8): 1})\n",
            "Game 24\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.04 0.88 0.04]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.115]\n",
            "Counter({(8, 9): 23, (7, 8): 1})\n",
            "Game 25\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0385 0.8846 0.0385]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.12 ]\n",
            "Counter({(8, 9): 24, (7, 8): 1})\n",
            "Game 26\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.037  0.8889 0.037 ]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.125]\n",
            "Counter({(8, 9): 25, (7, 8): 1})\n",
            "Game 27\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0357 0.8929 0.0357]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.13 ]\n",
            "Counter({(8, 9): 26, (7, 8): 1})\n",
            "Game 28\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0345 0.8966 0.0345]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.135]\n",
            "Counter({(8, 9): 27, (7, 8): 1})\n",
            "Game 29\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0333 0.9    0.0333]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.14 ]\n",
            "Counter({(8, 9): 28, (7, 8): 1})\n",
            "Game 30\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0323 0.9032 0.0323]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.145]\n",
            "Counter({(8, 9): 29, (7, 8): 1})\n",
            "Game 31\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0312 0.9062 0.0312]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.15 ]\n",
            "Counter({(8, 9): 30, (7, 8): 1})\n",
            "Game 32\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0303 0.9091 0.0303]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.155]\n",
            "Counter({(8, 9): 31, (7, 8): 1})\n",
            "Game 33\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0294 0.9118 0.0294]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.16 ]\n",
            "Counter({(8, 9): 32, (7, 8): 1})\n",
            "Game 34\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0286 0.9143 0.0286]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.165]\n",
            "Counter({(8, 9): 33, (7, 8): 1})\n",
            "Game 35\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0278 0.9167 0.0278]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.17 ]\n",
            "Counter({(8, 9): 34, (7, 8): 1})\n",
            "Game 36\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.027  0.9189 0.027 ]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.175]\n",
            "Counter({(8, 9): 35, (7, 8): 1})\n",
            "Game 37\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0263 0.9211 0.0263]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.18 ]\n",
            "Counter({(8, 9): 36, (7, 8): 1})\n",
            "Game 38\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0256 0.9231 0.0256]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.185]\n",
            "Counter({(8, 9): 37, (7, 8): 1})\n",
            "Game 39\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.025 0.925 0.025]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.19 ]\n",
            "Counter({(8, 9): 38, (7, 8): 1})\n",
            "Game 40\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0244 0.9268 0.0244]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.195]\n",
            "Counter({(8, 9): 39, (7, 8): 1})\n",
            "Game 41\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0238 0.9286 0.0238]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.2  ]\n",
            "Counter({(8, 9): 40, (7, 8): 1})\n",
            "Game 42\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0233 0.9302 0.0233]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.205]\n",
            "Counter({(8, 9): 41, (7, 8): 1})\n",
            "Game 43\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0227 0.9318 0.0227]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.21 ]\n",
            "Counter({(8, 9): 42, (7, 8): 1})\n",
            "Game 44\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0222 0.9333 0.0222]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.215]\n",
            "Counter({(8, 9): 43, (7, 8): 1})\n",
            "Game 45\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0217 0.9348 0.0217]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.22 ]\n",
            "Counter({(8, 9): 44, (7, 8): 1})\n",
            "Game 46\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0213 0.9362 0.0213]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.225]\n",
            "Counter({(8, 9): 45, (7, 8): 1})\n",
            "Game 47\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0208 0.9375 0.0208]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.23 ]\n",
            "Counter({(8, 9): 46, (7, 8): 1})\n",
            "Game 48\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0204 0.9388 0.0204]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.235]\n",
            "Counter({(8, 9): 47, (7, 8): 1})\n",
            "Game 49\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.02 0.94 0.02]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.24 ]\n",
            "Counter({(8, 9): 48, (7, 8): 1})\n",
            "Game 50\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0196 0.9412 0.0196]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.245]\n",
            "Counter({(8, 9): 49, (7, 8): 1})\n",
            "Game 51\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0192 0.9423 0.0192]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.25 ]\n",
            "Counter({(8, 9): 50, (7, 8): 1})\n",
            "Game 52\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0189 0.9434 0.0189]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.255]\n",
            "Counter({(8, 9): 51, (7, 8): 1})\n",
            "Game 53\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0185 0.9444 0.0185]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.26 ]\n",
            "Counter({(8, 9): 52, (7, 8): 1})\n",
            "Game 54\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0182 0.9455 0.0182]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.265]\n",
            "Counter({(8, 9): 53, (7, 8): 1})\n",
            "Game 55\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0179 0.9464 0.0179]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.27 ]\n",
            "Counter({(8, 9): 54, (7, 8): 1})\n",
            "Game 56\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0175 0.9474 0.0175]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.275]\n",
            "Counter({(8, 9): 55, (7, 8): 1})\n",
            "Game 57\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0172 0.9483 0.0172]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.28 ]\n",
            "Counter({(8, 9): 56, (7, 8): 1})\n",
            "Game 58\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0169 0.9492 0.0169]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.285]\n",
            "Counter({(8, 9): 57, (7, 8): 1})\n",
            "Game 59\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0167 0.95   0.0167]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.29 ]\n",
            "Counter({(8, 9): 58, (7, 8): 1})\n",
            "Game 60\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0164 0.9508 0.0164]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.295]\n",
            "Counter({(8, 9): 59, (7, 8): 1})\n",
            "Game 61\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0161 0.9516 0.0161]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.3  ]\n",
            "Counter({(8, 9): 60, (7, 8): 1})\n",
            "Game 62\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0159 0.9524 0.0159]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.305]\n",
            "Counter({(8, 9): 61, (7, 8): 1})\n",
            "Game 63\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0156 0.9531 0.0156]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.31 ]\n",
            "Counter({(8, 9): 62, (7, 8): 1})\n",
            "Game 64\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0154 0.9538 0.0154]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.315]\n",
            "Counter({(8, 9): 63, (7, 8): 1})\n",
            "Game 65\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0152 0.9545 0.0152]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.32 ]\n",
            "Counter({(8, 9): 64, (7, 8): 1})\n",
            "Game 66\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0149 0.9552 0.0149]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.325]\n",
            "Counter({(8, 9): 65, (7, 8): 1})\n",
            "Game 67\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0147 0.9559 0.0147]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.33 ]\n",
            "Counter({(8, 9): 66, (7, 8): 1})\n",
            "Game 68\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0145 0.9565 0.0145]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.335]\n",
            "Counter({(8, 9): 67, (7, 8): 1})\n",
            "Game 69\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0143 0.9571 0.0143]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.34 ]\n",
            "Counter({(8, 9): 68, (7, 8): 1})\n",
            "Game 70\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0141 0.9577 0.0141]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.345]\n",
            "Counter({(8, 9): 69, (7, 8): 1})\n",
            "Game 71\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0139 0.9583 0.0139]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.35 ]\n",
            "Counter({(8, 9): 70, (7, 8): 1})\n",
            "Game 72\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0137 0.9589 0.0137]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.355]\n",
            "Counter({(8, 9): 71, (7, 8): 1})\n",
            "Game 73\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0135 0.9595 0.0135]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.36 ]\n",
            "Counter({(8, 9): 72, (7, 8): 1})\n",
            "Game 74\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0133 0.96   0.0133]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.365]\n",
            "Counter({(8, 9): 73, (7, 8): 1})\n",
            "Game 75\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0132 0.9605 0.0132]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.37 ]\n",
            "Counter({(8, 9): 74, (7, 8): 1})\n",
            "Game 76\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.013 0.961 0.013]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.375]\n",
            "Counter({(8, 9): 75, (7, 8): 1})\n",
            "Game 77\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0128 0.9615 0.0128]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.38 ]\n",
            "Counter({(8, 9): 76, (7, 8): 1})\n",
            "Game 78\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0127 0.962  0.0127]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.385]\n",
            "Counter({(8, 9): 77, (7, 8): 1})\n",
            "Game 79\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0125 0.9625 0.0125]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.39 ]\n",
            "Counter({(8, 9): 78, (7, 8): 1})\n",
            "Game 80\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0123 0.963  0.0123]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.395]\n",
            "Counter({(8, 9): 79, (7, 8): 1})\n",
            "Game 81\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0122 0.9634 0.0122]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.4  ]\n",
            "Counter({(8, 9): 80, (7, 8): 1})\n",
            "Game 82\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.012  0.9639 0.012 ]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.405]\n",
            "Counter({(8, 9): 81, (7, 8): 1})\n",
            "Game 83\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0119 0.9643 0.0119]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.41 ]\n",
            "Counter({(8, 9): 82, (7, 8): 1})\n",
            "Game 84\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0118 0.9647 0.0118]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.415]\n",
            "Counter({(8, 9): 83, (7, 8): 1})\n",
            "Game 85\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0116 0.9651 0.0116]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.42 ]\n",
            "Counter({(8, 9): 84, (7, 8): 1})\n",
            "Game 86\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0115 0.9655 0.0115]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.425]\n",
            "Counter({(8, 9): 85, (7, 8): 1})\n",
            "Game 87\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0114 0.9659 0.0114]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.43 ]\n",
            "Counter({(8, 9): 86, (7, 8): 1})\n",
            "Game 88\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0112 0.9663 0.0112]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.435]\n",
            "Counter({(8, 9): 87, (7, 8): 1})\n",
            "Game 89\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0111 0.9667 0.0111]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.44 ]\n",
            "Counter({(8, 9): 88, (7, 8): 1})\n",
            "Game 90\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.011 0.967 0.011]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.445]\n",
            "Counter({(8, 9): 89, (7, 8): 1})\n",
            "Game 91\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0109 0.9674 0.0109]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.45 ]\n",
            "Counter({(8, 9): 90, (7, 8): 1})\n",
            "Game 92\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0108 0.9677 0.0108]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.455]\n",
            "Counter({(8, 9): 91, (7, 8): 1})\n",
            "Game 93\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0106 0.9681 0.0106]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.46 ]\n",
            "Counter({(8, 9): 92, (7, 8): 1})\n",
            "Game 94\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0105 0.9684 0.0105]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.465]\n",
            "Counter({(8, 9): 93, (7, 8): 1})\n",
            "Game 95\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0104 0.9688 0.0104]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.47 ]\n",
            "Counter({(8, 9): 94, (7, 8): 1})\n",
            "Game 96\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0103 0.9691 0.0103]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.475]\n",
            "Counter({(8, 9): 95, (7, 8): 1})\n",
            "Game 97\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0102 0.9694 0.0102]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.48 ]\n",
            "Counter({(8, 9): 96, (7, 8): 1})\n",
            "Game 98\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0101 0.9697 0.0101]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.485]\n",
            "Counter({(8, 9): 97, (7, 8): 1})\n",
            "Game 99\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.01 0.97 0.01]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.49 ]\n",
            "Counter({(8, 9): 98, (7, 8): 1})\n",
            "Game 100\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0099 0.9703 0.0099]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.495]\n",
            "Counter({(8, 9): 99, (7, 8): 1})\n",
            "Game 101\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0098 0.9706 0.0098]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.5  ]\n",
            "Counter({(8, 9): 100, (7, 8): 1})\n",
            "Game 102\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0097 0.9709 0.0097]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.505]\n",
            "Counter({(8, 9): 101, (7, 8): 1})\n",
            "Game 103\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0096 0.9712 0.0096]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.51 ]\n",
            "Counter({(8, 9): 102, (7, 8): 1})\n",
            "Game 104\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0095 0.9714 0.0095]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.515]\n",
            "Counter({(8, 9): 103, (7, 8): 1})\n",
            "Game 105\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0094 0.9717 0.0094]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.52 ]\n",
            "Counter({(8, 9): 104, (7, 8): 1})\n",
            "Game 106\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0093 0.972  0.0093]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.525]\n",
            "Counter({(8, 9): 105, (7, 8): 1})\n",
            "Game 107\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0093 0.9722 0.0093]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.53 ]\n",
            "Counter({(8, 9): 106, (7, 8): 1})\n",
            "Game 108\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0092 0.9725 0.0092]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.535]\n",
            "Counter({(8, 9): 107, (7, 8): 1})\n",
            "Game 109\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0091 0.9727 0.0091]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.54 ]\n",
            "Counter({(8, 9): 108, (7, 8): 1})\n",
            "Game 110\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.009 0.973 0.009]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.545]\n",
            "Counter({(8, 9): 109, (7, 8): 1})\n",
            "Game 111\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0089 0.9732 0.0089]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.55 ]\n",
            "Counter({(8, 9): 110, (7, 8): 1})\n",
            "Game 112\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0088 0.9735 0.0088]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.555]\n",
            "Counter({(8, 9): 111, (7, 8): 1})\n",
            "Game 113\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0088 0.9737 0.0088]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.56 ]\n",
            "Counter({(8, 9): 112, (7, 8): 1})\n",
            "Game 114\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0087 0.9739 0.0087]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.565]\n",
            "Counter({(8, 9): 113, (7, 8): 1})\n",
            "Game 115\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0086 0.9741 0.0086]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.57 ]\n",
            "Counter({(8, 9): 114, (7, 8): 1})\n",
            "Game 116\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0085 0.9744 0.0085]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.575]\n",
            "Counter({(8, 9): 115, (7, 8): 1})\n",
            "Game 117\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0085 0.9746 0.0085]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.58 ]\n",
            "Counter({(8, 9): 116, (7, 8): 1})\n",
            "Game 118\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0084 0.9748 0.0084]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.585]\n",
            "Counter({(8, 9): 117, (7, 8): 1})\n",
            "Game 119\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0083 0.975  0.0083]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.59 ]\n",
            "Counter({(8, 9): 118, (7, 8): 1})\n",
            "Game 120\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0083 0.9752 0.0083]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.595]\n",
            "Counter({(8, 9): 119, (7, 8): 1})\n",
            "Game 121\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0082 0.9754 0.0082]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.6  ]\n",
            "Counter({(8, 9): 120, (7, 8): 1})\n",
            "Game 122\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0081 0.9756 0.0081]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.605]\n",
            "Counter({(8, 9): 121, (7, 8): 1})\n",
            "Game 123\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0081 0.9758 0.0081]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.61 ]\n",
            "Counter({(8, 9): 122, (7, 8): 1})\n",
            "Game 124\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.008 0.976 0.008]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.615]\n",
            "Counter({(8, 9): 123, (7, 8): 1})\n",
            "Game 125\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0079 0.9762 0.0079]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.62 ]\n",
            "Counter({(8, 9): 124, (7, 8): 1})\n",
            "Game 126\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0079 0.9764 0.0079]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.625]\n",
            "Counter({(8, 9): 125, (7, 8): 1})\n",
            "Game 127\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0078 0.9766 0.0078]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.63 ]\n",
            "Counter({(8, 9): 126, (7, 8): 1})\n",
            "Game 128\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0078 0.9767 0.0078]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.635]\n",
            "Counter({(8, 9): 127, (7, 8): 1})\n",
            "Game 129\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0077 0.9769 0.0077]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.64 ]\n",
            "Counter({(8, 9): 128, (7, 8): 1})\n",
            "Game 130\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0076 0.9771 0.0076]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.645]\n",
            "Counter({(8, 9): 129, (7, 8): 1})\n",
            "Game 131\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0076 0.9773 0.0076]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.65 ]\n",
            "Counter({(8, 9): 130, (7, 8): 1})\n",
            "Game 132\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0075 0.9774 0.0075]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.655]\n",
            "Counter({(8, 9): 131, (7, 8): 1})\n",
            "Game 133\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0075 0.9776 0.0075]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.66 ]\n",
            "Counter({(8, 9): 132, (7, 8): 1})\n",
            "Game 134\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0074 0.9778 0.0074]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.665]\n",
            "Counter({(8, 9): 133, (7, 8): 1})\n",
            "Game 135\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0074 0.9779 0.0074]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.67 ]\n",
            "Counter({(8, 9): 134, (7, 8): 1})\n",
            "Game 136\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0073 0.9781 0.0073]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.675]\n",
            "Counter({(8, 9): 135, (7, 8): 1})\n",
            "Game 137\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0072 0.9783 0.0072]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.68 ]\n",
            "Counter({(8, 9): 136, (7, 8): 1})\n",
            "Game 138\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0072 0.9784 0.0072]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.685]\n",
            "Counter({(8, 9): 137, (7, 8): 1})\n",
            "Game 139\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0071 0.9786 0.0071]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.69 ]\n",
            "Counter({(8, 9): 138, (7, 8): 1})\n",
            "Game 140\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0071 0.9787 0.0071]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.695]\n",
            "Counter({(8, 9): 139, (7, 8): 1})\n",
            "Game 141\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.007  0.9789 0.007 ]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.7  ]\n",
            "Counter({(8, 9): 140, (7, 8): 1})\n",
            "Game 142\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.007 0.979 0.007]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.705]\n",
            "Counter({(8, 9): 141, (7, 8): 1})\n",
            "Game 143\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0069 0.9792 0.0069]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.71 ]\n",
            "Counter({(8, 9): 142, (7, 8): 1})\n",
            "Game 144\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0069 0.9793 0.0069]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.715]\n",
            "Counter({(8, 9): 143, (7, 8): 1})\n",
            "Game 145\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0068 0.9795 0.0068]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.72 ]\n",
            "Counter({(8, 9): 144, (7, 8): 1})\n",
            "Game 146\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0068 0.9796 0.0068]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.725]\n",
            "Counter({(8, 9): 145, (7, 8): 1})\n",
            "Game 147\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0068 0.9797 0.0068]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.73 ]\n",
            "Counter({(8, 9): 146, (7, 8): 1})\n",
            "Game 148\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0067 0.9799 0.0067]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.735]\n",
            "Counter({(8, 9): 147, (7, 8): 1})\n",
            "Game 149\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0067 0.98   0.0067]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.74 ]\n",
            "Counter({(8, 9): 148, (7, 8): 1})\n",
            "Game 150\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0066 0.9801 0.0066]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.745]\n",
            "Counter({(8, 9): 149, (7, 8): 1})\n",
            "Game 151\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0066 0.9803 0.0066]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.75 ]\n",
            "Counter({(8, 9): 150, (7, 8): 1})\n",
            "Game 152\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0065 0.9804 0.0065]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.755]\n",
            "Counter({(8, 9): 151, (7, 8): 1})\n",
            "Game 153\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0065 0.9805 0.0065]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.76 ]\n",
            "Counter({(8, 9): 152, (7, 8): 1})\n",
            "Game 154\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0065 0.9806 0.0065]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.765]\n",
            "Counter({(8, 9): 153, (7, 8): 1})\n",
            "Game 155\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0064 0.9808 0.0064]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.77 ]\n",
            "Counter({(8, 9): 154, (7, 8): 1})\n",
            "Game 156\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0064 0.9809 0.0064]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.775]\n",
            "Counter({(8, 9): 155, (7, 8): 1})\n",
            "Game 157\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0063 0.981  0.0063]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.78 ]\n",
            "Counter({(8, 9): 156, (7, 8): 1})\n",
            "Game 158\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0063 0.9811 0.0063]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.785]\n",
            "Counter({(8, 9): 157, (7, 8): 1})\n",
            "Game 159\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0063 0.9812 0.0063]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.79 ]\n",
            "Counter({(8, 9): 158, (7, 8): 1})\n",
            "Game 160\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0062 0.9814 0.0062]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.795]\n",
            "Counter({(8, 9): 159, (7, 8): 1})\n",
            "Game 161\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0062 0.9815 0.0062]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.8  ]\n",
            "Counter({(8, 9): 160, (7, 8): 1})\n",
            "Game 162\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0061 0.9816 0.0061]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.805]\n",
            "Counter({(8, 9): 161, (7, 8): 1})\n",
            "Game 163\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0061 0.9817 0.0061]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.81 ]\n",
            "Counter({(8, 9): 162, (7, 8): 1})\n",
            "Game 164\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0061 0.9818 0.0061]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.815]\n",
            "Counter({(8, 9): 163, (7, 8): 1})\n",
            "Game 165\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.006  0.9819 0.006 ]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.82 ]\n",
            "Counter({(8, 9): 164, (7, 8): 1})\n",
            "Game 166\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.006 0.982 0.006]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.825]\n",
            "Counter({(8, 9): 165, (7, 8): 1})\n",
            "Game 167\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.006  0.9821 0.006 ]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.83 ]\n",
            "Counter({(8, 9): 166, (7, 8): 1})\n",
            "Game 168\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0059 0.9822 0.0059]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.835]\n",
            "Counter({(8, 9): 167, (7, 8): 1})\n",
            "Game 169\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0059 0.9824 0.0059]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.84 ]\n",
            "Counter({(8, 9): 168, (7, 8): 1})\n",
            "Game 170\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0058 0.9825 0.0058]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.845]\n",
            "Counter({(8, 9): 169, (7, 8): 1})\n",
            "Game 171\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0058 0.9826 0.0058]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.85 ]\n",
            "Counter({(8, 9): 170, (7, 8): 1})\n",
            "Game 172\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0058 0.9827 0.0058]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.855]\n",
            "Counter({(8, 9): 171, (7, 8): 1})\n",
            "Game 173\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0057 0.9828 0.0057]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.86 ]\n",
            "Counter({(8, 9): 172, (7, 8): 1})\n",
            "Game 174\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0057 0.9829 0.0057]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.865]\n",
            "Counter({(8, 9): 173, (7, 8): 1})\n",
            "Game 175\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0057 0.983  0.0057]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.87 ]\n",
            "Counter({(8, 9): 174, (7, 8): 1})\n",
            "Game 176\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0056 0.9831 0.0056]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.875]\n",
            "Counter({(8, 9): 175, (7, 8): 1})\n",
            "Game 177\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0056 0.9831 0.0056]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.88 ]\n",
            "Counter({(8, 9): 176, (7, 8): 1})\n",
            "Game 178\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0056 0.9832 0.0056]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.885]\n",
            "Counter({(8, 9): 177, (7, 8): 1})\n",
            "Game 179\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0056 0.9833 0.0056]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.89 ]\n",
            "Counter({(8, 9): 178, (7, 8): 1})\n",
            "Game 180\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0055 0.9834 0.0055]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.895]\n",
            "Counter({(8, 9): 179, (7, 8): 1})\n",
            "Game 181\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0055 0.9835 0.0055]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.9  ]\n",
            "Counter({(8, 9): 180, (7, 8): 1})\n",
            "Game 182\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0055 0.9836 0.0055]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.905]\n",
            "Counter({(8, 9): 181, (7, 8): 1})\n",
            "Game 183\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0054 0.9837 0.0054]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.91 ]\n",
            "Counter({(8, 9): 182, (7, 8): 1})\n",
            "Game 184\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0054 0.9838 0.0054]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.915]\n",
            "Counter({(8, 9): 183, (7, 8): 1})\n",
            "Game 185\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0054 0.9839 0.0054]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.92 ]\n",
            "Counter({(8, 9): 184, (7, 8): 1})\n",
            "Game 186\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0053 0.984  0.0053]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.925]\n",
            "Counter({(8, 9): 185, (7, 8): 1})\n",
            "Game 187\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0053 0.984  0.0053]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.93 ]\n",
            "Counter({(8, 9): 186, (7, 8): 1})\n",
            "Game 188\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0053 0.9841 0.0053]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.935]\n",
            "Counter({(8, 9): 187, (7, 8): 1})\n",
            "Game 189\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0053 0.9842 0.0053]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.94 ]\n",
            "Counter({(8, 9): 188, (7, 8): 1})\n",
            "Game 190\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0052 0.9843 0.0052]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.945]\n",
            "Counter({(8, 9): 189, (7, 8): 1})\n",
            "Game 191\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0052 0.9844 0.0052]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.95 ]\n",
            "Counter({(8, 9): 190, (7, 8): 1})\n",
            "Game 192\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0052 0.9845 0.0052]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.955]\n",
            "Counter({(8, 9): 191, (7, 8): 1})\n",
            "Game 193\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0052 0.9845 0.0052]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.96 ]\n",
            "Counter({(8, 9): 192, (7, 8): 1})\n",
            "Game 194\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0051 0.9846 0.0051]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.965]\n",
            "Counter({(8, 9): 193, (7, 8): 1})\n",
            "Game 195\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0051 0.9847 0.0051]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.97 ]\n",
            "Counter({(8, 9): 194, (7, 8): 1})\n",
            "Game 196\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0051 0.9848 0.0051]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.975]\n",
            "Counter({(8, 9): 195, (7, 8): 1})\n",
            "Game 197\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.0051 0.9848 0.0051]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.98 ]\n",
            "Counter({(8, 9): 196, (7, 8): 1})\n",
            "Game 198\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.005  0.9849 0.005 ]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.985]\n",
            "Counter({(8, 9): 197, (7, 8): 1})\n",
            "Game 199\n",
            "_____________________\n",
            "                                \n",
            "Maximizer finds its target 2 agent:\n",
            "[0, 4]  op:(1, 1)\n",
            "fla_max_fre\n",
            "[0.005 0.985 0.005]\n",
            "Minimizer finds its target agents:\n",
            "[8, 9]\n",
            "min_fre\n",
            "[0.005 0.99 ]\n",
            "Counter({(8, 9): 198, (7, 8): 1})\n",
            "Game 200\n",
            "_____________________\n",
            "MAX_last_100,  all\n",
            "[1.] [0.005 0.985 0.005]\n",
            "[15] [  0  15 103]\n",
            "Max Nodes:[0, 4] Opinion: (1, 1)\n",
            "MIN_last_100,  all\n",
            "[1.] [0.005 0.99 ]\n",
            "Counter({(8, 9): 100}) Counter({(8, 9): 198, (7, 8): 1})\n",
            "Max Pol: 0.7241221433318702  Min Pol: 0.7205003332883541\n"
          ]
        }
      ],
      "source": [
        "Game_rounds = 200\n",
        "## Testing use\n",
        "k = 2\n",
        "experiment = 1\n",
        "h = len_actions(k, n)\n",
        "result = excute(h, k, Game_rounds)\n",
        "# save_(result, k, experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tjcFtF1AO2z"
      },
      "outputs": [],
      "source": [
        "def save_(result, k, experiment):\n",
        "    (First_max, First_min, max_touched, min_touched, payoff_matrix, min_history, fla_min_fre, min_history_last_100, min_touched_last_100, min_touched_all, max_history, fla_max_fre, max_history_last_100, equi_max, equi_min) = result\n",
        "    pd.DataFrame(payoff_matrix).to_csv('Payoff Matrix'+ str(k) +'.'+str(experiment)+'.csv')\n",
        "    \n",
        "    with open('Result'+ str(k) +'.'+str(experiment)+'.txt', \"a\") as f:\n",
        "        print('Initial Condition -(agent, opinion, pol)', file=f)\n",
        "#         print('Innate op'+str(s),file=f)\n",
        "#         print('Adjacency matrix'+ str(G), file=f)\n",
        "#         print('Selected Nodeset, k_Opinions, Steady-state polarization',file=f)\n",
        "        print('Max:'+ str(First_max), file=f)\n",
        "        print('Min' + str(First_min), file=f)\n",
        "        \n",
        "        print('_____________________', file=f)\n",
        "        print('Max Pol: '+str(equi_max)+\"  Min Pol: \"+str(equi_min))\n",
        "        # MAXimizer's distribution of LAST 100 iteration \n",
        "        print('Max_distribution_last_100',file = f)  \n",
        "        max_l100_fre = max_history_last_100/100\n",
        "        print(max_l100_fre [np.nonzero(max_l100_fre)],file = f)\n",
        "        # print for small network\n",
        "        #print(max_history_last_100)\n",
        "        # # Print for Large Network\n",
        "        print(np.nonzero(max_l100_fre),file = f)\n",
        "        columns = np.nonzero(max_l100_fre)\n",
        "        columns = list(columns[0])\n",
        "        for column in columns:\n",
        "            (k_nodes, opinions) = map_action(n,k,column)\n",
        "            print('  Max Nodes:'+ str(k_nodes)+' Opinion: '+ str(opinions), file = f)\n",
        "\n",
        "\n",
        "        print('Max_distribution_all',file = f)\n",
        "        max_fre = max_history/Game_rounds\n",
        "        print(max_fre[np.nonzero(max_fre)],file = f)\n",
        "        print([np.nonzero(max_fre)],file = f)\n",
        "        columns_all = np.nonzero(max_l100_fre)\n",
        "        columns_all = list(columns_all[0])\n",
        "        for column in columns_all:\n",
        "            (k_nodes, opinions) =  map_action(n,k,column)\n",
        "            print('  Max Nodes:'+ str(k_nodes)+' Opinion: '+ str(opinions), file = f)\n",
        "\n",
        "\n",
        "        # MINimizer's Strategy in the last 100 round\n",
        "        counter=collections.Counter(min_touched_last_100)\n",
        "        fla_min_fre = np.array(list(counter.values()))/(100) #return only frequency of all min options in order\n",
        "        print('Min_distribution_last_100',file = f)\n",
        "        print(fla_min_fre,file = f)\n",
        "        print(counter,file = f)\n",
        "        # print(min_touched_last_100)\n",
        "\n",
        "        counter_1=collections.Counter(min_touched_all)  #return a dictionary include {'min_option': count of this choice}\n",
        "        fla_min_fre_1 = np.array(list(counter_1.values()))/Game_rounds #return only frequency of all min options in order\n",
        "        print('Min_distribution_all',file = f)\n",
        "        print(fla_min_fre_1,file = f)\n",
        "        print(counter_1,file = f)\n",
        "        np.set_printoptions(precision=3)\n",
        "\n",
        "        counter_a=collections.Counter(min_history)  #return a dictionary include {'min_option': count of this choice}\n",
        "        print(counter_a, file=f)\n",
        "\n",
        "        print('min_recent_'+str(memory)+'_touched', file=f)# then stop at Game 202\n",
        "        print(min_touched, file=f)\n",
        "        print('max_recent_'+str(memory)+'_touched', file=f)\n",
        "        print(max_touched, file=f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToEJYxYAAO20"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vqg7vzUKAO2x"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}