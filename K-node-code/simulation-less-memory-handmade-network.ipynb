{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### This code is from Updated Testing Reddit - No Con- bias (Fictitious Play)-01092022\n",
    "##### This code replace the big real data network with small synthetic network\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import collections\n",
    "import sys\n",
    "import scipy.optimize\n",
    "import os\n",
    "import os.path\n",
    "from game import Game, exportGameResult\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Fixed initial condition + memeory = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathmatic Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'manual'\n",
    "# network_name = 'reddit'\n",
    "# network_name = 'karate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = import_network(network_name)\n",
    "G, s, n = network.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the Network Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Laplacian matrix\n",
    "L = scipy.sparse.csgraph.laplacian(G, normed=False)\n",
    "# A = (I + L)^(-1) - Stanford paper theory\n",
    "A = np.linalg.inv(np.identity(n) + L)\n",
    "nxG = nx.from_numpy_array(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Equilibrium & Polarization \n",
    "$$P(z) = z ^T * z $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Innate Op and Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fictitious Play Start !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Innate_polarization:\t0.41022891110361115\n",
      "Equi_polarization:\t0.04411213470472514\n",
      "Difference:\t\t-0.366116776398886\n"
     ]
    }
   ],
   "source": [
    "# Calculate network polarization\n",
    "calculate_polarization(s, n, A, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Parameters\n",
    "game_rounds = 20\n",
    "memory = 10\n",
    "k = 2\n",
    "experiment = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes, opinions\n",
      "[1, 2] (0, 0)\n",
      "Nodes, opinions\n",
      "[0, 3] (0.5, 0.5)\n",
      "min_history [((0, 3), (0.5, 0.5))]\n",
      "--------------------\n",
      "Game 1\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [1.]\n",
      "Max_por 0.09181344162282333\n",
      "Max_por 0.10085992937712412\n",
      "Max_por 0.1244223977280837\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.009 0.042 0.042 0.092 0.    0.    0.    0.\n",
      " 0.037 0.081 0.101 0.022 0.    0.    0.    0.    0.056 0.07  0.124 0.016\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.5\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.    0.245] 0.05258526212463719\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.5 0.5]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.05258526212463719 and Equi_Max = 0.1244223977280837\n",
      "--------------------\n",
      "Game 2\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.5 0.5]\n",
      "Max_por 0.0840967180334859\n",
      "Max_por 0.10428579672201099\n",
      "Max_por 0.11187313273619545\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.008 0.037 0.037 0.084 0.    0.    0.    0.\n",
      " 0.028 0.104 0.089 0.043 0.    0.    0.    0.    0.047 0.093 0.112 0.035\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.6666666666666666\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.    0.296] 0.06803615015737091\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.333 0.333 0.333]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.06803615015737091 and Equi_Max = 0.11187313273619545\n",
      "--------------------\n",
      "Game 3\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.333 0.333 0.333]\n",
      "Max_por 0.08132234147310835\n",
      "Max_por 0.11191318908429851\n",
      "Max_por 0.11191318908429851\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.007 0.035 0.035 0.081 0.    0.    0.    0.\n",
      " 0.026 0.112 0.085 0.049 0.    0.    0.    0.    0.044 0.1   0.108 0.042\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 25\n",
      "Maximizer found its target 2 agent: [1, 4] op: (0, 1)\n",
      "fre_max at spot 0.25\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.208 0.401] 0.0807048279140988\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.25 0.25 0.25 0.25]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.0807048279140988 and Equi_Max = 0.11191318908429851\n",
      "--------------------\n",
      "Game 4\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.25 0.25 0.25 0.25]\n",
      "Max_por 0.08082884686112524\n",
      "Max_por 0.11019188853438519\n",
      "Max_por 0.11019188853438519\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.007 0.035 0.035 0.081 0.    0.    0.    0.\n",
      " 0.025 0.11  0.085 0.047 0.    0.    0.    0.    0.043 0.098 0.107 0.04\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 25\n",
      "Maximizer found its target 2 agent: [1, 4] op: (0, 1)\n",
      "fre_max at spot 0.4\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.409 0.463] 0.08364073678854489\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.2 0.2 0.2 0.2 0.2]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.08364073678854489 and Equi_Max = 0.11019188853438519\n",
      "--------------------\n",
      "Game 5\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.2 0.2 0.2 0.2 0.2]\n",
      "Max_por 0.08208598423587563\n",
      "Max_por 0.10568740694904344\n",
      "Max_por 0.1094154300146799\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.007 0.035 0.035 0.082 0.    0.    0.    0.\n",
      " 0.027 0.106 0.087 0.043 0.    0.    0.    0.    0.045 0.094 0.109 0.036\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.5\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.291 0.452] 0.08869942746396622\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.167 0.167 0.167 0.167 0.167 0.167]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.08869942746396622 and Equi_Max = 0.1094154300146799\n",
      "--------------------\n",
      "Game 6\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.167 0.167 0.167 0.167 0.167 0.167]\n",
      "Max_por 0.0820551817347217\n",
      "Max_por 0.10429178647120498\n",
      "Max_por 0.10962211769203943\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.035 0.035 0.082 0.    0.    0.    0.\n",
      " 0.027 0.104 0.087 0.042 0.    0.    0.    0.    0.045 0.093 0.11  0.035\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.5714285714285714\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.207 0.444] 0.09149547392300536\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.143 0.143 0.143 0.143 0.143 0.143 0.143]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.09149547392300536 and Equi_Max = 0.10962211769203943\n",
      "--------------------\n",
      "Game 7\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 4 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.143 0.143 0.143 0.143 0.143 0.143 0.143]\n",
      "Max_por 0.08161796169582008\n",
      "Max_por 0.10439577481429006\n",
      "Max_por 0.10913731411013787\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.035 0.035 0.082 0.    0.    0.    0.\n",
      " 0.027 0.104 0.086 0.042 0.    0.    0.    0.    0.045 0.093 0.109 0.035\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.625\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.144 0.439] 0.0931455456294853\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.0931455456294853 and Equi_Max = 0.10913731411013787\n",
      "--------------------\n",
      "Game 8\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 5 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "Max_por 0.0810734300807555\n",
      "Max_por 0.10525207591296519\n",
      "Max_por 0.10841454461655145\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.035 0.035 0.081 0.    0.    0.    0.\n",
      " 0.026 0.105 0.086 0.043 0.    0.    0.    0.    0.044 0.093 0.108 0.035\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.6666666666666666\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.095 0.434] 0.09416406768990335\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.111 0.111 0.111 0.111 0.111 0.111 0.111 0.111 0.111]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.09416406768990335 and Equi_Max = 0.10841454461655145\n",
      "--------------------\n",
      "Game 9\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 6 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.111 0.111 0.111 0.111 0.111 0.111 0.111 0.111 0.111]\n",
      "Max_por 0.0805295755479503\n",
      "Max_por 0.10648560830474742\n",
      "Max_por 0.10763350738327586\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.035 0.035 0.081 0.    0.    0.    0.\n",
      " 0.026 0.106 0.085 0.044 0.    0.    0.    0.    0.044 0.095 0.108 0.036\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.7\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.056 0.43 ] 0.09481201910012602\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.09481201910012602 and Equi_Max = 0.10763350738327586\n",
      "--------------------\n",
      "Game 10\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 7 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "Max_por 0.08002454098633377\n",
      "Max_por 0.10789773554880956\n",
      "Max_por 0.10789773554880956\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.08  0.    0.    0.    0.\n",
      " 0.025 0.108 0.084 0.045 0.    0.    0.    0.    0.043 0.096 0.107 0.037\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 25\n",
      "Maximizer found its target 2 agent: [1, 4] op: (0, 1)\n",
      "fre_max at spot 0.2727272727272727\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.161 0.456] 0.0966297588624844\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.0966297588624844 and Equi_Max = 0.10789773554880956\n",
      "--------------------\n",
      "Game 11\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263)), ((0, 3), (0.1609887576363637, 0.4560467236363636))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 7 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091]\n",
      "Max_por 0.07980370446436783\n",
      "Max_por 0.10804654867043635\n",
      "Max_por 0.10804654867043635\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.08  0.    0.    0.    0.\n",
      " 0.025 0.108 0.084 0.045 0.    0.    0.    0.    0.043 0.096 0.107 0.037\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 25\n",
      "Maximizer found its target 2 agent: [1, 4] op: (0, 1)\n",
      "fre_max at spot 0.3333333333333333\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.249 0.478] 0.09733902473954689\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.083 0.083 0.083 0.083 0.083 0.083 0.083 0.083 0.083 0.083 0.083 0.083]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.09733902473954689 and Equi_Max = 0.10804654867043635\n",
      "--------------------\n",
      "Game 12\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263)), ((0, 3), (0.1609887576363637, 0.4560467236363636)), ((0, 3), (0.2487851185482456, 0.47753782015789464))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 7 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.083 0.083 0.083 0.083 0.083 0.083 0.083 0.083 0.083 0.083 0.083 0.083]\n",
      "Max_por 0.07983375250320224\n",
      "Max_por 0.10746878320590442\n",
      "Max_por 0.10746878320590442\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.08  0.    0.    0.    0.\n",
      " 0.025 0.107 0.084 0.044 0.    0.    0.    0.    0.043 0.095 0.107 0.037\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 25\n",
      "Maximizer found its target 2 agent: [1, 4] op: (0, 1)\n",
      "fre_max at spot 0.38461538461538464\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.323 0.496] 0.09736720787227823\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077\n",
      " 0.077]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.09736720787227823 and Equi_Max = 0.10746878320590442\n",
      "--------------------\n",
      "Game 13\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263)), ((0, 3), (0.1609887576363637, 0.4560467236363636)), ((0, 3), (0.2487851185482456, 0.47753782015789464)), ((0, 3), (0.32307434701214577, 0.49572259413765174))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 7 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077 0.077\n",
      " 0.077]\n",
      "Max_por 0.0800703842902904\n",
      "Max_por 0.10647576899168527\n",
      "Max_por 0.10717856029307352\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.08  0.    0.    0.    0.\n",
      " 0.026 0.106 0.085 0.043 0.    0.    0.    0.    0.044 0.095 0.107 0.036\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.5714285714285714\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.279 0.489] 0.0983443426988014\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071\n",
      " 0.071 0.071]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.0983443426988014 and Equi_Max = 0.10717856029307352\n",
      "--------------------\n",
      "Game 14\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263)), ((0, 3), (0.1609887576363637, 0.4560467236363636)), ((0, 3), (0.2487851185482456, 0.47753782015789464)), ((0, 3), (0.32307434701214577, 0.49572259413765174)), ((0, 3), (0.2787145698609023, 0.488691221518797))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 8 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071 0.071\n",
      " 0.071 0.071]\n",
      "Max_por 0.08015010014025088\n",
      "Max_por 0.10589972052454899\n",
      "Max_por 0.10736775074680543\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.08  0.    0.    0.    0.\n",
      " 0.026 0.106 0.085 0.043 0.    0.    0.    0.    0.044 0.094 0.107 0.035\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.6\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.24  0.483] 0.09903938698689083\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.067 0.067 0.067 0.067 0.067 0.067 0.067 0.067 0.067 0.067 0.067 0.067\n",
      " 0.067 0.067 0.067]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.09903938698689083 and Equi_Max = 0.10736775074680543\n",
      "--------------------\n",
      "Game 15\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263)), ((0, 3), (0.1609887576363637, 0.4560467236363636)), ((0, 3), (0.2487851185482456, 0.47753782015789464)), ((0, 3), (0.32307434701214577, 0.49572259413765174)), ((0, 3), (0.2787145698609023, 0.488691221518797)), ((0, 3), (0.24026942966315787, 0.4825973652491228))]\n",
      "max_history [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 9 0 0\n",
      " 0 0 0]\n",
      "fla_min_fre [0.067 0.067 0.067 0.067 0.067 0.067 0.067 0.067 0.067 0.067 0.067 0.067\n",
      " 0.067 0.067 0.067]\n",
      "Max_por 0.08012972416279675\n",
      "Max_por 0.10563312956335466\n",
      "Max_por 0.10739545194390579\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.08  0.    0.    0.    0.\n",
      " 0.026 0.106 0.085 0.043 0.    0.    0.    0.    0.044 0.094 0.107 0.035\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.625\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.207 0.477] 0.0995319173424653\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062\n",
      " 0.062 0.062 0.062 0.062]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.0995319173424653 and Equi_Max = 0.10739545194390579\n",
      "--------------------\n",
      "Game 16\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263)), ((0, 3), (0.1609887576363637, 0.4560467236363636)), ((0, 3), (0.2487851185482456, 0.47753782015789464)), ((0, 3), (0.32307434701214577, 0.49572259413765174)), ((0, 3), (0.2787145698609023, 0.488691221518797)), ((0, 3), (0.24026942966315787, 0.4825973652491228)), ((0, 3), (0.20662993199013152, 0.47726524101315787))]\n",
      "max_history [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "  0  5  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
      "fla_min_fre [0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062 0.062\n",
      " 0.062 0.062 0.062 0.062]\n",
      "Max_por 0.08004573461371922\n",
      "Max_por 0.10559793611884108\n",
      "Max_por 0.10731513862869643\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.08  0.    0.    0.    0.\n",
      " 0.026 0.106 0.085 0.043 0.    0.    0.    0.    0.044 0.094 0.107 0.035\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.6470588235294118\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.177 0.473] 0.09987687706514572\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059\n",
      " 0.059 0.059 0.059 0.059 0.059]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.09987687706514572 and Equi_Max = 0.10731513862869643\n",
      "--------------------\n",
      "Game 17\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263)), ((0, 3), (0.1609887576363637, 0.4560467236363636)), ((0, 3), (0.2487851185482456, 0.47753782015789464)), ((0, 3), (0.32307434701214577, 0.49572259413765174)), ((0, 3), (0.2787145698609023, 0.488691221518797)), ((0, 3), (0.24026942966315787, 0.4825973652491228)), ((0, 3), (0.20662993199013152, 0.47726524101315787)), ((0, 3), (0.1769480222786378, 0.4725604255108359))]\n",
      "max_history [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "  0  5  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
      "fla_min_fre [0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059 0.059\n",
      " 0.059 0.059 0.059 0.059 0.059]\n",
      "Max_por 0.07992195526603768\n",
      "Max_por 0.10573664541595054\n",
      "Max_por 0.10716272097343117\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.08  0.    0.    0.    0.\n",
      " 0.026 0.106 0.085 0.043 0.    0.    0.    0.    0.044 0.094 0.107 0.035\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.6666666666666666\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.151 0.468] 0.10011296903863715\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056\n",
      " 0.056 0.056 0.056 0.056 0.056 0.056]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.10011296903863715 and Equi_Max = 0.10716272097343117\n",
      "--------------------\n",
      "Game 18\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263)), ((0, 3), (0.1609887576363637, 0.4560467236363636)), ((0, 3), (0.2487851185482456, 0.47753782015789464)), ((0, 3), (0.32307434701214577, 0.49572259413765174)), ((0, 3), (0.2787145698609023, 0.488691221518797)), ((0, 3), (0.24026942966315787, 0.4825973652491228)), ((0, 3), (0.20662993199013152, 0.47726524101315787)), ((0, 3), (0.1769480222786378, 0.4725604255108359)), ((0, 3), (0.15056410253508776, 0.4683783672865497))]\n",
      "max_history [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "  0  5  0  0  0  0  0  0  0  0 12  0  0  0  0  0]\n",
      "fla_min_fre [0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056 0.056\n",
      " 0.056 0.056 0.056 0.056 0.056 0.056]\n",
      "Max_por 0.07977414896084323\n",
      "Max_por 0.10600637792553262\n",
      "Max_por 0.10696269322263408\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.08  0.    0.    0.    0.\n",
      " 0.025 0.106 0.085 0.043 0.    0.    0.    0.    0.044 0.094 0.107 0.035\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.6842105263157895\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.127 0.465] 0.10026793443142677\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053\n",
      " 0.053 0.053 0.053 0.053 0.053 0.053 0.053]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.10026793443142677 and Equi_Max = 0.10696269322263408\n",
      "--------------------\n",
      "Game 19\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263)), ((0, 3), (0.1609887576363637, 0.4560467236363636)), ((0, 3), (0.2487851185482456, 0.47753782015789464)), ((0, 3), (0.32307434701214577, 0.49572259413765174)), ((0, 3), (0.2787145698609023, 0.488691221518797)), ((0, 3), (0.24026942966315787, 0.4825973652491228)), ((0, 3), (0.20662993199013152, 0.47726524101315787)), ((0, 3), (0.1769480222786378, 0.4725604255108359)), ((0, 3), (0.15056410253508776, 0.4683783672865497)), ((0, 3), (0.1269574375013851, 0.46463652571745157))]\n",
      "max_history [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "  0  5  0  0  0  0  0  0  0  0 13  0  0  0  0  0]\n",
      "fla_min_fre [0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053 0.053\n",
      " 0.053 0.053 0.053 0.053 0.053 0.053 0.053]\n",
      "Max_por 0.07961283881593577\n",
      "Max_por 0.106374804631349\n",
      "Max_por 0.10673197125052088\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.08  0.    0.    0.    0.\n",
      " 0.025 0.106 0.084 0.043 0.    0.    0.    0.    0.043 0.094 0.107 0.035\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 34\n",
      "Maximizer found its target 2 agent: [2, 4] op: (1, 0)\n",
      "fre_max at spot 0.7\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.106 0.461] 0.1003619613887675\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.1003619613887675 and Equi_Max = 0.10673197125052088\n",
      "--------------------\n",
      "Game 20\n",
      "----------\n",
      "min_history [((0, 3), (0.5, 0.5)), ((0, 3), (0.0, 0.2454970247368421)), ((0, 3), (0.0, 0.2960924756491228)), ((0, 3), (0.20789970559210524, 0.4005543272105263)), ((0, 3), (0.4092287821894737, 0.46323143814736845)), ((0, 3), (0.2913635629736842, 0.4522400947017544)), ((0, 3), (0.20717412067669183, 0.44438913509774447)), ((0, 3), (0.14403203895394734, 0.43850091539473685)), ((0, 3), (0.09492153094736845, 0.4339211889590643)), ((0, 3), (0.055633124542105325, 0.4302574078105263)), ((0, 3), (0.1609887576363637, 0.4560467236363636)), ((0, 3), (0.2487851185482456, 0.47753782015789464)), ((0, 3), (0.32307434701214577, 0.49572259413765174)), ((0, 3), (0.2787145698609023, 0.488691221518797)), ((0, 3), (0.24026942966315787, 0.4825973652491228)), ((0, 3), (0.20662993199013152, 0.47726524101315787)), ((0, 3), (0.1769480222786378, 0.4725604255108359)), ((0, 3), (0.15056410253508776, 0.4683783672865497)), ((0, 3), (0.1269574375013851, 0.46463652571745157)), ((0, 3), (0.10571143897105269, 0.4612688683052632))]\n",
      "max_history [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "  0  5  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
      "fla_min_fre [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n",
      "Max_por 0.0794450834299055\n",
      "Max_por 0.10681732022503496\n",
      "Max_por 0.10681732022503496\n",
      "all_por [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.006 0.034 0.034 0.079 0.    0.    0.    0.\n",
      " 0.025 0.107 0.084 0.043 0.    0.    0.    0.    0.043 0.095 0.106 0.036\n",
      " 0.    0.    0.    0.   ]\n",
      "column - best action: 25\n",
      "Maximizer found its target 2 agent: [1, 4] op: (0, 1)\n",
      "fre_max at spot 0.2857142857142857\n",
      "M\n",
      "[[-0.019 -0.019 -0.019 -0.005  0.062]]\n",
      "M\n",
      "[[-0.127 -0.127  0.001 -0.055  0.309]]\n",
      "M\n",
      "[[-0.031  0.146  0.169 -0.063 -0.22 ]]\n",
      "champion:  [0, 3] [0.159 0.473] 0.10093726990312196\n",
      "Minimizer finds its target agents: [0, 3]\n",
      "fla_min_fre: [0.048 0.048 0.048 0.048 0.048 0.048 0.048 0.048 0.048 0.048 0.048 0.048\n",
      " 0.048 0.048 0.048 0.048 0.048 0.048 0.048 0.048 0.048]\n",
      "Not Reached Nash Equilibrium at Equi_Min = 0.10093726990312196 and Equi_Max = 0.10681732022503496\n",
      "MAX_last_100,  all\n",
      "[0.06 0.14] [0.05 0.3  0.7 ]\n",
      "[25 34] [16 25 34]\n",
      "Max Nodes: [1, 4] | Opinion: (0, 1)\n",
      "Max Nodes: [2, 4] | Opinion: (1, 0)\n",
      "MIN_last_100,  all\n",
      "[0.2] [1.05]\n",
      "Counter({(0, 3): 20}) Counter({(0, 3): 21})\n",
      "Max Pol: 0.10681732022503496 Min Pol: 0.10093726990312196\n"
     ]
    }
   ],
   "source": [
    "# configure the game\n",
    "game = Game(s, A, L, k)\n",
    "# run the game\n",
    "result = game.run(game_rounds, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportGameResult(network_name, game, result, k, memory, experiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
