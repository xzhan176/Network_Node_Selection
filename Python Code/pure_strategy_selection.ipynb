{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###     Maximizer's Choice\n",
    "\n",
    "Innate greedy algorithm (polarization):\n",
    "\n",
    "For each $i$ from $1$ to $k$, we choose $v_i$ such that:\n",
    "\n",
    "$$v_i = argmax_{v \\in V - \\hat{s}} \\max \\left(\\bar{s}_1^T \\bar{s}_1, \\bar{s}_0^T \\bar{s}_0 \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines if value of opinion at v should be set to 0 or 1 to maximize equilibrium polarization \n",
    "def maximize_equi_polarization(op, n, v1):\n",
    "    \n",
    "    innat_equi_por = obj_innate_polarization(op, n)\n",
    "    temp = op[v1, 0]\n",
    "    por_arr = np.zeros(2)\n",
    "#     print(por_arr)\n",
    "    \n",
    "#     max_opi_option = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    max_opi_option = [0.0, 1.0]\n",
    "    \n",
    "    # objective if set opinion to 0, 0.1, ..., 1.0\n",
    "    i = 0\n",
    "    for new_op in max_opi_option:\n",
    "#         print('change op to '+ str(i/10))\n",
    "        \n",
    "        op[v1, 0] = new_op\n",
    "        por_arr[i] = obj_polarization(A, L, op, n)\n",
    "#         print(por_arr[i])\n",
    "        i = i + 1\n",
    "        op[v1, 0] = temp\n",
    "#     print(por_arr)\n",
    "    \n",
    "    \n",
    "    maxmize_op = np.argmax(por_arr)\n",
    "    max_por = np.max(por_arr)\n",
    " \n",
    "#     print('new_op', 'innat_equi_por', 'max_por')\n",
    "#     print(maxmize_op, innat_equi_por, max_por)\n",
    "\n",
    "    return (maxmize_op, innat_equi_por, max_por)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_max_vertex(op, n, min_touched):\n",
    "    # iterate over all the vertices that have not yet been changed\n",
    "    #vertices = np.where((op != 0.0) & (op != 1.0))\n",
    "    # current best vertex, its opinion {0, 1}, \"innate\" objective, and objective\n",
    "    \n",
    "    innat_equi_por = obj_polarization(A, L, op, n)\n",
    "#     print(\"innate equi por to compare\")\n",
    "#     print(innat_equi_por)\n",
    "    \n",
    "    champion = (None, None, 0, innat_equi_por)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    for v1 in c1:\n",
    "        print('Max start with agent '+ str(v1) )\n",
    "        if v1 not in min_touched:\n",
    "            (maxmize_op, innat_equi_por, max_por) = maximize_equi_polarization(op, n, v1)\n",
    "\n",
    "            if max_por >= champion[3]:\n",
    "                champion = (v1, maxmize_op, innat_equi_por, max_por)\n",
    "    end = time.perf_counter()\n",
    "    print(f'Finished in {round(end-start, 2)} second(s)') \n",
    "    return (champion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizer's Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines if a given vertex should be set to zero or one, all else equal\n",
    "def minimize_opinion(s, n, v2):\n",
    "    \n",
    "    # minimizer's options\n",
    "    #min_opi_option = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    minimize_op = derivate_s(s, n, v2)# find min_s_star for each max_action\n",
    "    \n",
    "    op = copy.copy(s)\n",
    "    op[v2, 0] = minimize_op\n",
    "    \n",
    "    min_pol = obj_polarization(A, L, op, n)\n",
    "\n",
    "    return (minimize_op, min_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_min_vertex(s, n, max_touched):\n",
    "    # current best vertex, its opinion {0, 1}, \"innate\" objective, and  current best objective\n",
    "    \n",
    "    innat_equi_por = obj_polarization(A, L, s, n)\n",
    "#     print(\"innate equi por to compare\")\n",
    "#     print(innat_equi_por)\n",
    "\n",
    "    champion = (None, None, 0, innat_equi_por)\n",
    "    \n",
    "    for v2 in c1:\n",
    "        if v2 not in max_touched:\n",
    "            print('Min start with agent '+ str(v2) )\n",
    "#             print('Current opinion array')\n",
    "#             print(op)\n",
    "            \n",
    "            (minimize_op, min_pol) = minimize_opinion(s, n, v2)  \n",
    "#             print('minimize opinion')\n",
    "#             print(minimize_op, min_pol)\n",
    "            if min_pol <= champion[3]:\n",
    "                champion = (v2, minimize_op, innat_equi_por, min_pol)\n",
    "\n",
    "    return (champion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game play  - Pure Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Op has been updated by maximizer, so minimizer react to the innate op after that\n",
    "def minimizer_play(s,v1,max_opinion,n, max_touched): \n",
    "    \n",
    "    op = copy.copy(s)\n",
    "    #update innat opinion \n",
    "    op[v1,0] = max_opinion\n",
    "    print('_______________________')\n",
    "    print('Minimizer Play')\n",
    "#     print('Only 1 opinion changed')\n",
    "#     print(op)\n",
    "    \n",
    "    min_champion = choose_min_vertex(op, n, max_touched)\n",
    "    (v2, min_opinion, innat_equi_por, min_pol) = min_champion\n",
    "    \n",
    "    if v2 == None:\n",
    "        print('Minimizer fail')\n",
    "\n",
    "    else:\n",
    "        print(\"                                \")\n",
    "        print(\"Minimizer finds its target agent:\")\n",
    "#         print('v2', 'changed_opinion', 'innate_obj', 'obj')\n",
    "#         print(v2, min_opinion, innat_equi_por, min_pol)\n",
    "        #Store innate_op of the min_selected vertex\n",
    "        old_opinion_min = op[v2,0]\n",
    "        ##### change the agent's opinion\n",
    "        op[v2,0] = min_opinion   #-------------------------------------------------> store minimize strategy\n",
    "\n",
    "\n",
    "        print(\"    \"+\"Agent\" + str(v2) +\" 's opinion \" + str(old_opinion_min) + \" changed to \"+ str(min_opinion))\n",
    "\n",
    "        print(\"Network reaches equilibrium Polarization: \" + str(min_pol))\n",
    "#         print('2 opinion changed')\n",
    "#         print(op)\n",
    "\n",
    "    return (v2,min_opinion, min_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximizer_play(s,v2,min_opinion,n,min_touched): \n",
    "    op = copy.copy(s)\n",
    "    #update innat opinion \n",
    "    op[v2,0] = min_opinion  # Op has been updated by minimizer, so maximizer react to the innate op after that\n",
    "#     print('Only 1 opinion changed')\n",
    "#     print(op)\n",
    "    \n",
    "\n",
    "    max_champion = choose_max_vertex(op, n, min_touched) # The best choice among all opinions and vertexs\n",
    "    (v1, max_opinion, innate_obj, max_pol) = max_champion\n",
    "\n",
    "    if v1 == None:\n",
    "        print('Maximizer fail')\n",
    "\n",
    "    else:\n",
    "        print(\"                                \")\n",
    "        print(\"Maximizer finds its target agent:\")\n",
    "#         print('v1', 'changed_opinion', 'innate_obj', 'obj')\n",
    "#         print(max_champion)\n",
    "\n",
    "        #Store innate_op of the max_selected vertex\n",
    "        old_opinion_max = op[v1, 0]\n",
    "        ##### change the agent's opinion\n",
    "        op[v1,0] = max_opinion\n",
    "        ## check if agent's opinionis is changed or not\n",
    "        print(\"    \"+\"Agent\" + str(v1) +\" 's opinion \" + str(old_opinion_max) + \" changed to \"+ str(max_opinion))\n",
    "#         print(\"Network reaches equilibrium Polarization: \" + str(max_pol))\n",
    "#         print('2 opinion changed')\n",
    "#         print(op)\n",
    "\n",
    "    return(v1, max_opinion, max_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
