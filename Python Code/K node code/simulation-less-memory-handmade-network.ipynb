{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### This code is from Updated Testing Reddit - No Con- bias (Fictitious Play)-01092022\n",
    "##### This code replace the big real datanetwork with small sythetic network\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import collections\n",
    "import sys\n",
    "import scipy.optimize\n",
    "import os\n",
    "import os.path\n",
    "from math import comb\n",
    "from game import Game, GameResult\n",
    "from utils import *\n",
    "\n",
    "save_path = os.getcwd()\n",
    "\n",
    "calculate_polarization = calculate_polarization1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Fixed initial condition + memeory = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathmatic Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'karate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network = import_network(network_name)\n",
    "\n",
    "# G, s, n = network.init()\n",
    "# nxG = nx.from_numpy_array(G)\n",
    "\n",
    "# ############################ Make Innate Opinion ################################\n",
    "\n",
    "# # Calculate Key Values & Visualization #######################################3\n",
    "# # the Laplacian matrix\n",
    "# L = scipy.sparse.csgraph.laplacian(G, normed=False)\n",
    "# A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)  Adjacency Matrix\n",
    "# # call the function to calculate the number of edges\n",
    "# m = num_edges(L, n)\n",
    "# columnsum_ij = np.sum(A, axis=0)\n",
    "# plt.figure(figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make this a network import called 'manual'\n",
    "\n",
    "# # #################### Import Sythetic Network Data\n",
    "df = pd.read_csv (save_path+'/data/5Adj_matrix.csv', header=None)\n",
    "G = np.array(df[df.columns[:]])\n",
    "# # # print(G)\n",
    "df1 = pd.read_csv(save_path+'/data/5innate_op.csv', header = None)\n",
    "s = np.array(df1[df1.columns[:]])\n",
    "\n",
    "# print(s)\n",
    "# print(G.shape)\n",
    "\n",
    "# # Set n according to the data\n",
    "n = len(s[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Process the Network Data\n",
    "L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "m = num_edges(L, n)                    # call the function to calculate the number of edges\n",
    "# what the twitter graph looks like\n",
    "nxG = nx.from_numpy_array(G)\n",
    "#plt.figure(figsize=(20, 20))\n",
    "# nx.draw(nxG).\n",
    "columnsum_ij = np.sum(A, axis=0)\n",
    "print(columnsum_ij)\n",
    "# s = [0.5]*n\n",
    "# s = np.reshape(s, (n, 1))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Equilibrium & Polarization \n",
    "$$P(z) = z ^T * z $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Innate Op and Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fictitious Play Start !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate network polarization\n",
    "calculate_polarization(s, n, A, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Parameters\n",
    "game_rounds = 3\n",
    "memory = 10\n",
    "k = 2\n",
    "experiment = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the game\n",
    "game = Game(s, A, L, k)\n",
    "# run the game\n",
    "result = game.run(game_rounds, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(result: GameResult, k, experiment):\n",
    "    pd.DataFrame(result.payoff_matrix).to_csv(\n",
    "        f'results/Payoff-Matrix-k-{k}-experiment-{experiment}.csv')\n",
    "\n",
    "    # Save the original standard output\n",
    "    original_stdout = sys.stdout\n",
    "\n",
    "    with open(f'results/Result-k-{k}-experiment-{experiment}.txt', \"w\") as f:\n",
    "        # Change the standard output to the file we created.\n",
    "        sys.stdout = f\n",
    "\n",
    "        print('Initial Condition -(agent, opinion, pol)')\n",
    "        # print(f'Innate op {s}')\n",
    "        # print(f'Adjacency matrix {G}')\n",
    "        # print('Selected Nodeset, k_Opinions, Steady-state polarization')\n",
    "        print(f'Max:\\t{result.first_max}')\n",
    "        print(f'Min:\\t{result.first_min}')\n",
    "\n",
    "        print('_____________________')\n",
    "        print(f'Max Pol:\\t{result.equi_max}')\n",
    "        print(f'Min Pol:\\t{result.equi_min}')\n",
    "\n",
    "        # MAXimizer's distribution of LAST 100 iteration\n",
    "        print('Max_distribution_last_100')\n",
    "        max_l100_fre = result.max_history_last_100/100\n",
    "        print(max_l100_fre[np.nonzero(max_l100_fre)])\n",
    "        # print for small network\n",
    "        # print(max_history_last_100)\n",
    "        # # Print for Large Network\n",
    "        print(np.nonzero(max_l100_fre))\n",
    "\n",
    "        columns = np.nonzero(max_l100_fre)\n",
    "        columns = list(columns[0])\n",
    "        for column in columns:\n",
    "            (k_nodes, opinions) = game.map_action(column)\n",
    "            print(f'Max Nodes: {k_nodes}\\tOpinion: {opinions}')\n",
    "\n",
    "        print('Max_distribution_all')\n",
    "        max_fre = result.max_history/result.game_rounds\n",
    "        print(max_fre[np.nonzero(max_fre)])\n",
    "        print([np.nonzero(max_fre)])\n",
    "\n",
    "        # TODO confirm isn't this block the same as the one above\n",
    "        columns_all = np.nonzero(max_l100_fre)\n",
    "        columns_all = list(columns_all[0])\n",
    "        for column in columns_all:\n",
    "            (k_nodes, opinions) = game.map_action(column)\n",
    "            print(f'Max Nodes: {k_nodes}\\tOpinion: {opinions}')\n",
    "\n",
    "        # MINimizer's Strategy in the last 100 round\n",
    "        counter = collections.Counter(result.min_touched_last_100)\n",
    "        # frequency of all min options in order\n",
    "        fla_min_fre = np.array(list(counter.values()))/(100)\n",
    "        print('Min_distribution_last_100')\n",
    "        print(fla_min_fre)\n",
    "        print(counter)\n",
    "        # print(min_touched_last_100)\n",
    "\n",
    "        # a dictionary include {'min_option': count of this choice}\n",
    "        counter_1 = collections.Counter(result.min_touched_all)\n",
    "        # frequency of all min options in order\n",
    "        fla_min_fre_1 = np.array(list(counter_1.values()))/result.game_rounds\n",
    "        print('Min_distribution_all')\n",
    "        print(fla_min_fre_1)\n",
    "        print(counter_1)\n",
    "        np.set_printoptions(precision=3)\n",
    "\n",
    "        # a dictionary include {'min_option': count of this choice}\n",
    "        counter_a = collections.Counter(result.min_history)\n",
    "        print(counter_a)\n",
    "\n",
    "        print(f'min_recent_{memory}_touched')\n",
    "        print(result.min_touched)\n",
    "        print(f'max_recent_{memory}_touched')\n",
    "        print(result.max_touched)\n",
    "\n",
    "        # Reset the standard output to its original value\n",
    "        sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(result, k, experiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
