{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(\"Reddit.mat\")\n",
    "n = data['Reddit'][0,0][0].shape[0]     # number of vertices = 556\n",
    "G = data['Reddit'][0,0][0].toarray()     # adjacency matrix in compressed sparse column format, convert to array\n",
    "nodemap = data['Reddit'][0, 0][1]     # mapping from node ID to labels 1-556 (not important)\n",
    "edges = data['Reddit'][0,0][2]     # list of edges (same as G, not used)\n",
    "s = data['Reddit'][0,0][5]     # labeled \"recent innate opinions\"\n",
    "\n",
    "# remove isolated vertices from the graph\n",
    "s = np.delete(s, 551)\n",
    "s = np.delete(s, 105)\n",
    "s = np.delete(s, 52)\n",
    "n -= 3\n",
    "s = s.reshape((n , 1))\n",
    "G = np.delete(G, 551, 1)\n",
    "G = np.delete(G, 551, 0)\n",
    "G = np.delete(G, 105, 1)\n",
    "G = np.delete(G, 105, 0)\n",
    "G = np.delete(G, 52, 1)\n",
    "G = np.delete(G, 52, 0)\n",
    "\n",
    "L = scipy.sparse.csgraph.laplacian(G, normed=False)  # Return the Laplacian matrix\n",
    "A = np.linalg.inv(np.identity(n) + L)  # A = (I + L)^(-1)\\n  Stanford paper theory\n",
    "m = num_edges(L, n)                    # call the function to calculate the number of edges\n",
    "columnsum_ij = np.sum(A, axis=0)\n",
    "# print(columnsum_ij)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_anl(s,n,G,agent):\n",
    "\n",
    "    print(str(agent)+' opinion: ' + str(s[agent]))\n",
    "    print(str(agent)+' neighbors: '+ str(np.nonzero(G[agent])))\n",
    "\n",
    "    s_aa = s[:, 0]\n",
    "    my_dict = {index: value for index, value in enumerate(s_aa)}\n",
    "    sorting_s = sorted(my_dict.items(), key=lambda x:x[1])\n",
    "    sorted_S = dict(sorting_s)\n",
    "\n",
    "    temp = list(sorted_S.items()) \n",
    "    res = [idx for idx, key in enumerate(temp) if key[0]==agent]\n",
    "    # printing result \n",
    "    print(\"Opinion rank of this agent is : \" + str(res))\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"___________________Max Analyze__________________________________________\")\n",
    "    nxG = nx.from_numpy_matrix(G) \n",
    "    # G = nx.karate_club_graph()\n",
    "    print(\"_______________Degree Centrality___________________\")  \n",
    "    deg_centrality = nx.degree_centrality(nxG)\n",
    "    sortedDict = sorted(deg_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict = dict(sortedDict)\n",
    "    temp1 = list(converted_dict.items()) \n",
    "    res1 = [idx for idx, key in enumerate(temp1) if key[0]==agent]\n",
    "    print(\"rank of this agent is : \" + str(res1))\n",
    "    print(converted_dict[agent])\n",
    "\n",
    "    # print(converted_dict)\n",
    "    print(\"                           \")\n",
    "    print(\"_______________Closeness Rank________________________\")\n",
    "    close_centrality = nx.closeness_centrality(nxG)\n",
    "    sortedDict1 = sorted(close_centrality.items(), key=lambda x:x[1])\n",
    "    converted_dict1 = dict(sortedDict1)\n",
    "    temp2 = list(converted_dict1.items()) \n",
    "    res2 = [idx for idx, key in enumerate(temp2) if key[0]==agent]\n",
    "    print(\"rank of this agent is : \" + str(res2))\n",
    "    print(converted_dict1[agent])\n",
    "    # print(converted_dict1)\n",
    "    print(\"                           \")\n",
    "    print(\"_______________Page Rank_____________________________\")\n",
    "    pr = nx.eigenvector_centrality(nxG)\n",
    "    sortedDict3 = sorted(pr.items(), key=lambda x:x[1])\n",
    "    converted_dict3 = dict(sortedDict3)\n",
    "    temp3 = list(converted_dict3.items()) \n",
    "    res3 = [idx for idx, key in enumerate(temp3) if key[0]==agent]\n",
    "    print(\"rank of this agent is : \" + str(res3))\n",
    "    print(converted_dict3[agent])\n",
    "    # print(converted_dict3)\n",
    "\n",
    "    print(\"                           \")\n",
    "\n",
    "    def gap(op, n):\n",
    "        ones = np.ones((n, 1))\n",
    "        x = op - (np.dot(np.transpose(op),ones)/n) * ones\n",
    "        return abs(x)\n",
    "\n",
    "    gap = gap(s,n)\n",
    "    my_gap = {index: value for index, value in enumerate(gap)}\n",
    "    sorting_gap = sorted(my_gap.items(), key=lambda x:x[1])\n",
    "    sorted_gap = dict(sorting_gap)\n",
    "    #print(sorted_gap)\n",
    "    temp4 = list(sorted_gap.items()) \n",
    "    res4 = [idx for idx, key in enumerate(temp4) if key[0]==agent]\n",
    "    print(\"Agent's opinion gap to mean opinion is ranked as: \" + str(res4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
